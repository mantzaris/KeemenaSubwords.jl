var documenterSearchIndex = {"docs":
[{"location":"integration/#Integration-With-KeemenaPreprocessing","page":"Integration","title":"Integration With KeemenaPreprocessing","text":"KeemenaSubwords tokenizers are callable and work with KeemenaPreprocessing's callable tokenizer contract.\n\nusing KeemenaPreprocessing\nusing KeemenaSubwords\n\ntokenizer = load_tokenizer(:core_bpe_en)\n\ncfg = PreprocessConfiguration(tokenizer_name = keemena_callable(tokenizer))\nbundle = preprocess_corpus([\"hello world\", \"hello keemena\"]; config=cfg)\n\n# KeemenaPreprocessing stores callable levels under Symbol(typeof(tokenizer))\nlvl = level_key(tokenizer)\nsubword_corpus = get_corpus(bundle, lvl)","category":"section"},{"location":"loading/#Loading-Tokenizers","page":"Loading","title":"Loading Tokenizers","text":"using KeemenaSubwords\n\n# built-in models\nbpe = load_tokenizer(:core_bpe_en)\nwp = load_tokenizer(:core_wordpiece_en)\nsp = load_tokenizer(:core_sentencepiece_unigram_en)\ntiktoken = load_tokenizer(:tiktoken_cl100k_base)\ngpt2 = load_tokenizer(:openai_gpt2_bpe)\nmistral_v1 = load_tokenizer(:mistral_v1_sentencepiece)\nphi2 = load_tokenizer(:phi2_bpe)\nqwen = load_tokenizer(:qwen2_5_bpe)\nbert_multi = load_tokenizer(:bert_base_multilingual_cased_wordpiece)\nxlmr = load_tokenizer(:xlm_roberta_base_sentencepiece_bpe)\n\n# directory/file auto-detection\nload_tokenizer(\"/path/to/model_dir\")\nload_tokenizer(\"/path/to/spm.model\")\nload_tokenizer(\"/path/to/encoding.tiktoken\")\nload_tokenizer(\"/path/to/tokenizer.json\"; format=:hf_tokenizer_json)\n\n# explicit BPE/ByteBPE paths\nload_tokenizer((\"/path/to/vocab.txt\", \"/path/to/merges.txt\"))\nload_tokenizer((\"/path/to/vocab.txt\", \"/path/to/merges.txt\"); format=:bytebpe)\n\n# GPT-2 style byte-level BPE\nload_tokenizer(\"/path/to/gpt2_dir\"; format=:bpe_gpt2)\n# also supports encoder.json + vocab.bpe filenames\n\n# named spec\nload_tokenizer((format=:bpe_gpt2, vocab=\"/path/to/vocab.txt\", merges=\"/path/to/merges.txt\"))\n\n# external user-supplied models (not shipped as built-ins)\nload_tokenizer(\"/path/to/tokenizer.model\")                                  # Llama 2 style SentencePiece\nload_tokenizer(\"/path/to/llama3_tokenizer.tiktoken\"; format=:tiktoken)      # Llama 3 style tiktoken\nload_tokenizer(\"/path/to/tekken_like.tiktoken\"; format=:tiktoken)           # Mistral Tekken-like file\n\n# installable gated models (requires accepted license + token)\ninstall_model!(:llama2_tokenizer; token=ENV[\"HF_TOKEN\"])\ninstall_model!(:llama3_8b_tokenizer; token=ENV[\"HF_TOKEN\"])\nload_tokenizer(:llama3_8b_tokenizer)\n\n# optional key registration for external assets\nregister_local_model!(\n    :my_llama_external,\n    \"/path/to/tokenizer.model\";\n    format=:sentencepiece_model,\n    family=:llama,\n    description=\"User-supplied Llama tokenizer\",\n)\nload_tokenizer(:my_llama_external)\n\n# optional authenticated Hugging Face download helper\ndownload_hf_files(\n    \"meta-llama/Llama-3.1-8B\",\n    [\"tokenizer.model\"];\n    revision=\"main\",\n    token=get(ENV, \"HF_TOKEN\", nothing),\n)\n\nLLaMA tokenizer files are gated by upstream license terms. KeemenaSubwords does not redistribute those assets and only installs them into your local cache when you call install_model!.","category":"section"},{"location":"models/#Built-In-Models","page":"Built-In Models","title":"Built-In Models","text":"using KeemenaSubwords\n\navailable_models()\navailable_models(format=:tiktoken)\navailable_models(format=:bpe_gpt2)\navailable_models(format=:hf_tokenizer_json)\navailable_models(family=:qwen)\navailable_models(family=:mistral)\navailable_models(distribution=:artifact_public)\navailable_models(distribution=:installable_gated)\navailable_models(shipped=true)\n\ndescribe_model(:core_bpe_en)\ndescribe_model(:core_wordpiece_en)\ndescribe_model(:core_sentencepiece_unigram_en)\ndescribe_model(:tiktoken_o200k_base)\ndescribe_model(:openai_gpt2_bpe)\ndescribe_model(:bert_base_uncased_wordpiece)\ndescribe_model(:bert_base_multilingual_cased_wordpiece)\ndescribe_model(:t5_small_sentencepiece_unigram)\ndescribe_model(:mistral_v1_sentencepiece)\ndescribe_model(:mistral_v3_sentencepiece)\ndescribe_model(:phi2_bpe)\ndescribe_model(:qwen2_5_bpe)\ndescribe_model(:roberta_base_bpe)\ndescribe_model(:xlm_roberta_base_sentencepiece_bpe)\ndescribe_model(:llama3_8b_tokenizer)\nrecommended_defaults_for_llms()\n\nmodel_path(:core_bpe_en)\n\nThe table below is generated from the same registry used by available_models() and describe_model(...).\n\n<!– KEEMENAMODELSSTART –> Generated from the registry by `tools/syncreadmemodels.jl(excluding:userlocal` entries)._","category":"section"},{"location":"models/#bpe-/-core","page":"Built-In Models","title":"bpe / core","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:core_bpe_en shipped MIT in-repo/core in-repo:core vocab.txt, merges.txt Tiny built-in English classic BPE model (vocab.txt + merges.txt).","category":"section"},{"location":"models/#bpe_gpt2-/-openai","page":"Built-In Models","title":"bpe_gpt2 / openai","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:openai_gpt2_bpe artifact_public MIT openaipublic/gpt-2 openaipublic:gpt-2/encodings/main vocab.json + merges.txt, encoder.json + vocab.bpe OpenAI GPT-2 byte-level BPE assets (encoder.json + vocab.bpe).","category":"section"},{"location":"models/#bpe_gpt2-/-phi","page":"Built-In Models","title":"bpe_gpt2 / phi","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:phi2_bpe artifact_public MIT microsoft/phi-2 huggingface:microsoft/phi-2@810d367871c1d460086d9f82db8696f2e0a0fcd0 vocab.json + merges.txt, encoder.json + vocab.bpe Microsoft Phi-2 GPT2-style tokenizer files (vocab.json + merges.txt).","category":"section"},{"location":"models/#bpe_gpt2-/-roberta","page":"Built-In Models","title":"bpe_gpt2 / roberta","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:roberta_base_bpe artifact_public MIT FacebookAI/roberta-base huggingface:FacebookAI/roberta-base@e2da8e2f811d1448a5b465c236feacd80ffbac7b vocab.json + merges.txt, encoder.json + vocab.bpe RoBERTa-base byte-level BPE tokenizer files (vocab.json + merges.txt).","category":"section"},{"location":"models/#hf_tokenizer_json-/-llama","page":"Built-In Models","title":"hf_tokenizer_json / llama","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:llama3_8b_tokenizer installable_gated Llama-3.1-Community-License meta-llama/Meta-Llama-3-8B-Instruct huggingface:meta-llama/Meta-Llama-3-8B-Instruct@main tokenizer.json (preferred), vocab.json + merges.txt (fallback) Meta Llama 3 8B tokenizer (gated; install with install_model!).","category":"section"},{"location":"models/#hf_tokenizer_json-/-qwen","page":"Built-In Models","title":"hf_tokenizer_json / qwen","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:qwen2_5_bpe artifact_public Apache-2.0 Qwen/Qwen2.5-7B huggingface:Qwen/Qwen2.5-7B@d149729398750b98c0af14eb82c78cfe92750796 tokenizer.json (preferred), vocab.json + merges.txt (fallback) Qwen2.5 BPE tokenizer assets (tokenizer.json with vocab/merges fallback).","category":"section"},{"location":"models/#sentencepiece_model-/-core","page":"Built-In Models","title":"sentencepiece_model / core","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:core_sentencepiece_unigram_en shipped MIT in-repo/core in-repo:core spm.model / tokenizer.model / tokenizer.model.v3 / sentencepiece.bpe.model Tiny built-in SentencePiece Unigram model (.model).","category":"section"},{"location":"models/#sentencepiece_model-/-llama","page":"Built-In Models","title":"sentencepiece_model / llama","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:llama2_tokenizer installable_gated Llama-2-Community-License meta-llama/Llama-2-7b-hf huggingface:meta-llama/Llama-2-7b-hf@main spm.model / tokenizer.model / tokenizer.model.v3 / sentencepiece.bpe.model Meta Llama 2 tokenizer (gated; install with install_model!).","category":"section"},{"location":"models/#sentencepiece_model-/-mistral","page":"Built-In Models","title":"sentencepiece_model / mistral","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:mistral_v1_sentencepiece artifact_public Apache-2.0 mistralai/Mixtral-8x7B-Instruct-v0.1 huggingface:mistralai/Mixtral-8x7B-Instruct-v0.1@eba92302a2861cdc0098cc54bc9f17cb2c47eb61 spm.model / tokenizer.model / tokenizer.model.v3 / sentencepiece.bpe.model Mistral/Mixtral tokenizer.model SentencePiece model.\n:mistral_v3_sentencepiece artifact_public Apache-2.0 mistralai/Mistral-7B-Instruct-v0.3 huggingface:mistralai/Mistral-7B-Instruct-v0.3@c170c708c41dac9275d15a8fff4eca08d52bab71 spm.model / tokenizer.model / tokenizer.model.v3 / sentencepiece.bpe.model Mistral-7B-Instruct-v0.3 tokenizer.model.v3 SentencePiece model.","category":"section"},{"location":"models/#sentencepiece_model-/-t5","page":"Built-In Models","title":"sentencepiece_model / t5","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:t5_small_sentencepiece_unigram artifact_public Apache-2.0 google-t5/t5-small huggingface:google-t5/t5-small@df1b051c49625cf57a3d0d8d3863ed4d13564fe4 spm.model / tokenizer.model / tokenizer.model.v3 / sentencepiece.bpe.model Hugging Face google-t5/t5-small SentencePiece model (Unigram).","category":"section"},{"location":"models/#sentencepiece_model-/-xlm_roberta","page":"Built-In Models","title":"sentencepiece_model / xlm_roberta","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:xlm_roberta_base_sentencepiece_bpe artifact_public MIT FacebookAI/xlm-roberta-base huggingface:FacebookAI/xlm-roberta-base@e73636d4f797dec63c3081bb6ed5c7b0bb3f2089 spm.model / tokenizer.model / tokenizer.model.v3 / sentencepiece.bpe.model XLM-RoBERTa-base sentencepiece.bpe.model file.","category":"section"},{"location":"models/#tiktoken-/-openai","page":"Built-In Models","title":"tiktoken / openai","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:tiktoken_cl100k_base artifact_public MIT openaipublic/encodings openaipublic:encodings/cl100k_base.tiktoken *.tiktoken OpenAI tiktoken cl100k_base encoding.\n:tiktoken_o200k_base artifact_public MIT openaipublic/encodings openaipublic:encodings/o200k_base.tiktoken *.tiktoken OpenAI tiktoken o200k_base encoding.\n:tiktoken_p50k_base artifact_public MIT openaipublic/encodings openaipublic:encodings/p50k_base.tiktoken *.tiktoken OpenAI tiktoken p50k_base encoding.\n:tiktoken_r50k_base artifact_public MIT openaipublic/encodings openaipublic:encodings/r50k_base.tiktoken *.tiktoken OpenAI tiktoken r50k_base encoding.","category":"section"},{"location":"models/#wordpiece_vocab-/-bert","page":"Built-In Models","title":"wordpiece_vocab / bert","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:bert_base_multilingual_cased_wordpiece artifact_public Apache-2.0 google-bert/bert-base-multilingual-cased huggingface:google-bert/bert-base-multilingual-cased@3f076fdb1ab68d5b2880cb87a0886f315b8146f8 vocab.txt Hugging Face bert-base-multilingual-cased WordPiece vocabulary.\n:bert_base_uncased_wordpiece artifact_public Apache-2.0 bert-base-uncased huggingface:bert-base-uncased@86b5e0934494bd15c9632b12f734a8a67f723594 vocab.txt Hugging Face bert-base-uncased WordPiece vocabulary.","category":"section"},{"location":"models/#wordpiece_vocab-/-core","page":"Built-In Models","title":"wordpiece_vocab / core","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:core_wordpiece_en shipped MIT in-repo/core in-repo:core vocab.txt Tiny built-in English WordPiece model.\n\n<!– KEEMENAMODELSEND –>\n\ndescribe_model(key) includes provenance metadata such as license, family, distribution, upstream_repo, upstream_ref, and upstream_files.\n\nBuilt-ins resolve from artifact paths when present, with in-repo fallback model files only for tiny :core_* assets.\n\nprefetch_models(recommended_defaults_for_llms())","category":"section"},{"location":"#KeemenaSubwords.jl","page":"Home","title":"KeemenaSubwords.jl","text":"Downstream of KeemenaPreprocessing.jl.\n\nCurrent implemented scope:\n\nclassic BPE,\nbyte-level BPE,\nWordPiece,\nUnigram,\nSentencePiece wrapper loading from .model.","category":"section"},{"location":"#Installation","page":"Home","title":"Installation","text":"] add https://github.com/mantzaris/KeemenaSubwords.jl","category":"section"},{"location":"#Quick-Start","page":"Home","title":"Quick Start","text":"using KeemenaSubwords\n\ntokenizer = load_tokenizer(:core_bpe_en)\npieces = tokenize(tokenizer, \"hello world\")\nids = encode(tokenizer, \"hello world\"; add_special_tokens=true)\ntext = decode(tokenizer, ids)\n\nlevel_key(tokenizer)","category":"section"},{"location":"#Built-in-models","page":"Home","title":"Built-in models","text":"available_models()\navailable_models(format=:bpe_gpt2)\navailable_models(format=:hf_tokenizer_json)\navailable_models(family=:mistral)\navailable_models(shipped=true)\ndescribe_model(:core_bpe_en)\ndescribe_model(:core_wordpiece_en)\ndescribe_model(:core_sentencepiece_unigram_en)\ndescribe_model(:tiktoken_cl100k_base)\ndescribe_model(:openai_gpt2_bpe)\ndescribe_model(:mistral_v1_sentencepiece)\ndescribe_model(:phi2_bpe)\ndescribe_model(:qwen2_5_bpe)\nrecommended_defaults_for_llms()\n\nFor the generated full inventory table, see the Built-In Models page. Use available_models(distribution=:artifact_public) for public artifact-backed built-ins and available_models(distribution=:installable_gated) for gated installable keys.\n\nPrefetch artifacts (when available) for offline use:\n\nprefetch_models([\n    :tiktoken_cl100k_base,\n    :openai_gpt2_bpe,\n    :mistral_v3_sentencepiece,\n    :qwen2_5_bpe,\n])\n\nOnly tiny :core_* assets ship in this repository. Most real model files are lazy artifacts resolved from Artifacts.toml. Gated assets are supported via external user-supplied paths.\n\nUse pure-Julia Hugging Face tokenizer loading when a model ships only tokenizer.json:\n\nload_tokenizer(\"/path/to/tokenizer.json\"; format=:hf_tokenizer_json)\n\nFor gated assets (for example LLaMA), use user-managed files and optional cache helpers:\n\nregister_local_model!(\n    :my_llama,\n    \"/path/to/tokenizer.model\";\n    format=:sentencepiece_model,\n    family=:llama,\n    description=\"Local LLaMA tokenizer\",\n)\n\ndownload_hf_files(\n    \"meta-llama/Llama-3.1-8B\",\n    [\"tokenizer.model\"];\n    revision=\"main\",\n    token=get(ENV, \"HF_TOKEN\", nothing),\n)\n\ninstall_model!(:llama3_8b_tokenizer; token=ENV[\"HF_TOKEN\"])\nload_tokenizer(:llama3_8b_tokenizer)","category":"section"},{"location":"#KeemenaPreprocessing-Integration","page":"Home","title":"KeemenaPreprocessing Integration","text":"using KeemenaPreprocessing\nusing KeemenaSubwords\n\ntokenizer = load_tokenizer(:core_bpe_en)\ncfg = PreprocessConfiguration(tokenizer_name = keemena_callable(tokenizer))\nbundle = preprocess_corpus([\"hello world\"]; config=cfg)\n\nlvl = level_key(tokenizer)\nsubword_corpus = get_corpus(bundle, lvl)","category":"section"},{"location":"#Save-and-Export","page":"Home","title":"Save and Export","text":"tok = load_tokenizer(:core_wordpiece_en)\nsave_tokenizer(tok, \"out/wp\")\nexport_tokenizer(tok, \"out/wp_vocab\"; format=:wordpiece_vocab)\n\nbpe = load_tokenizer(:core_bpe_en)\nexport_tokenizer(bpe, \"out/bpe\"; format=:bpe_gpt2)","category":"section"},{"location":"#Training-API","page":"Home","title":"Training API","text":"train_bpe(corpus; vocab_size=30_000)\ntrain_unigram(corpus; vocab_size=32_000)\ntrain_wordpiece(corpus; vocab_size=30_000)\n\nCurrent status:\n\ntrain_bpe and train_unigram are implemented baseline trainers.\ntrain_wordpiece is still intentionally unimplemented and throws ArgumentError.","category":"section"},{"location":"#API","page":"Home","title":"API","text":"","category":"section"},{"location":"#KeemenaSubwords.AbstractSubwordTokenizer","page":"Home","title":"KeemenaSubwords.AbstractSubwordTokenizer","text":"Abstract parent type for all subword tokenizers.\n\nTokenizers are callable and support: tokenizer(text::AbstractString) -> Vector{String}.\n\n\n\n\n\n","category":"type"},{"location":"#KeemenaSubwords.SubwordVocabulary","page":"Home","title":"KeemenaSubwords.SubwordVocabulary","text":"Vocabulary container with forward/reverse lookup and special token IDs.\n\nIDs are 1-based.\n\n\n\n\n\n","category":"type"},{"location":"#KeemenaSubwords.TokenizerMetadata","page":"Home","title":"KeemenaSubwords.TokenizerMetadata","text":"Common metadata for tokenizer instances.\n\n\n\n\n\n","category":"type"},{"location":"#KeemenaSubwords.available_models-Tuple{}","page":"Home","title":"KeemenaSubwords.available_models","text":"List available built-in model names.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.bos_id-Tuple{AbstractSubwordTokenizer}","page":"Home","title":"KeemenaSubwords.bos_id","text":"BOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.bos_id-Tuple{BPETokenizer}","page":"Home","title":"KeemenaSubwords.bos_id","text":"BOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.bos_id-Tuple{ByteBPETokenizer}","page":"Home","title":"KeemenaSubwords.bos_id","text":"BOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.bos_id-Tuple{SentencePieceTokenizer}","page":"Home","title":"KeemenaSubwords.bos_id","text":"BOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.bos_id-Tuple{SubwordVocabulary}","page":"Home","title":"KeemenaSubwords.bos_id","text":"Return beginning-of-sequence token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.bos_id-Tuple{TiktokenTokenizer}","page":"Home","title":"KeemenaSubwords.bos_id","text":"BOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.bos_id-Tuple{UnigramTokenizer}","page":"Home","title":"KeemenaSubwords.bos_id","text":"BOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.bos_id-Tuple{WordPieceTokenizer}","page":"Home","title":"KeemenaSubwords.bos_id","text":"BOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.decode-Tuple{AbstractSubwordTokenizer, AbstractVector{Int64}}","page":"Home","title":"KeemenaSubwords.decode","text":"Decode token IDs into text.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.decode-Tuple{BPETokenizer, AbstractVector{Int64}}","page":"Home","title":"KeemenaSubwords.decode","text":"Decode token IDs to text.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.decode-Tuple{ByteBPETokenizer, AbstractVector{Int64}}","page":"Home","title":"KeemenaSubwords.decode","text":"Decode byte-level BPE IDs back to text.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.decode-Tuple{SentencePieceTokenizer, AbstractVector{Int64}}","page":"Home","title":"KeemenaSubwords.decode","text":"Decode SentencePiece IDs back to text.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.decode-Tuple{TiktokenTokenizer, AbstractVector{Int64}}","page":"Home","title":"KeemenaSubwords.decode","text":"Decode tiktoken rank IDs to text.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.decode-Tuple{UnigramTokenizer, AbstractVector{Int64}}","page":"Home","title":"KeemenaSubwords.decode","text":"Decode unigram token IDs back to text.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.decode-Tuple{WordPieceTokenizer, AbstractVector{Int64}}","page":"Home","title":"KeemenaSubwords.decode","text":"Decode WordPiece token IDs back into text.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.describe_model-Tuple{Symbol}","page":"Home","title":"KeemenaSubwords.describe_model","text":"Describe a built-in model.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.download_hf_files-Tuple{AbstractString, AbstractVector{<:AbstractString}}","page":"Home","title":"KeemenaSubwords.download_hf_files","text":"Download selected files from a Hugging Face repository revision into cache.\n\nThis helper is opt-in and useful for user-managed / gated tokenizers.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.encode-Tuple{AbstractSubwordTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.encode","text":"Encode text into token IDs.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.encode-Tuple{BPETokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.encode","text":"Encode text to token IDs.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.encode-Tuple{ByteBPETokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.encode","text":"Encode text to byte-level BPE IDs.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.encode-Tuple{SentencePieceTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.encode","text":"Encode text to SentencePiece IDs.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.encode-Tuple{TiktokenTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.encode","text":"Encode text into tiktoken rank IDs (1-based in this package).\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.encode-Tuple{UnigramTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.encode","text":"Encode text to unigram token IDs.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.encode-Tuple{WordPieceTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.encode","text":"Encode text to WordPiece token IDs.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.eos_id-Tuple{AbstractSubwordTokenizer}","page":"Home","title":"KeemenaSubwords.eos_id","text":"EOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.eos_id-Tuple{BPETokenizer}","page":"Home","title":"KeemenaSubwords.eos_id","text":"EOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.eos_id-Tuple{ByteBPETokenizer}","page":"Home","title":"KeemenaSubwords.eos_id","text":"EOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.eos_id-Tuple{SentencePieceTokenizer}","page":"Home","title":"KeemenaSubwords.eos_id","text":"EOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.eos_id-Tuple{SubwordVocabulary}","page":"Home","title":"KeemenaSubwords.eos_id","text":"Return end-of-sequence token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.eos_id-Tuple{TiktokenTokenizer}","page":"Home","title":"KeemenaSubwords.eos_id","text":"EOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.eos_id-Tuple{UnigramTokenizer}","page":"Home","title":"KeemenaSubwords.eos_id","text":"EOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.eos_id-Tuple{WordPieceTokenizer}","page":"Home","title":"KeemenaSubwords.eos_id","text":"EOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.export_tokenizer-Tuple{AbstractSubwordTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.export_tokenizer","text":"Export tokenizer to external formats.\n\nSupported format values:\n\n:internal\n:bpe / :bpe_gpt2\n:wordpiece_vocab\n:unigram_tsv\n:sentencepiece_model\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.id_to_token-Tuple{AbstractSubwordTokenizer, Int64}","page":"Home","title":"KeemenaSubwords.id_to_token","text":"Reverse token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.id_to_token-Tuple{BPETokenizer, Int64}","page":"Home","title":"KeemenaSubwords.id_to_token","text":"Reverse token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.id_to_token-Tuple{ByteBPETokenizer, Int64}","page":"Home","title":"KeemenaSubwords.id_to_token","text":"Reverse token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.id_to_token-Tuple{SentencePieceTokenizer, Int64}","page":"Home","title":"KeemenaSubwords.id_to_token","text":"Reverse token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.id_to_token-Tuple{SubwordVocabulary, Int64}","page":"Home","title":"KeemenaSubwords.id_to_token","text":"Map ID to token string.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.id_to_token-Tuple{TiktokenTokenizer, Int64}","page":"Home","title":"KeemenaSubwords.id_to_token","text":"Reverse token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.id_to_token-Tuple{UnigramTokenizer, Int64}","page":"Home","title":"KeemenaSubwords.id_to_token","text":"Reverse token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.id_to_token-Tuple{WordPieceTokenizer, Int64}","page":"Home","title":"KeemenaSubwords.id_to_token","text":"Reverse token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.install_model!-Tuple{Symbol}","page":"Home","title":"KeemenaSubwords.install_model!","text":"Install an installable-gated tokenizer into the user cache and register it by key.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.keemena_callable-Tuple{AbstractSubwordTokenizer}","page":"Home","title":"KeemenaSubwords.keemena_callable","text":"Return a function compatible with KeemenaPreprocessing's callable tokenizer contract.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.level_key-Tuple{AbstractSubwordTokenizer}","page":"Home","title":"KeemenaSubwords.level_key","text":"Level key used by KeemenaPreprocessing for callable tokenizers.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.load_hf_tokenizer_json-Tuple{AbstractString}","page":"Home","title":"KeemenaSubwords.load_hf_tokenizer_json","text":"Load a Hugging Face tokenizer.json tokenizer in pure Julia.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.load_tokenizer-Tuple{AbstractString}","page":"Home","title":"KeemenaSubwords.load_tokenizer","text":"Load tokenizer from file system path.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.load_tokenizer-Tuple{NamedTuple}","page":"Home","title":"KeemenaSubwords.load_tokenizer","text":"Load tokenizer from a named specification.\n\nExamples:\n\n(format=:wordpiece, path=\"/.../vocab.txt\")\n(format=:bpe_gpt2, vocab=\"/.../vocab.txt\", merges=\"/.../merges.txt\")\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.load_tokenizer-Tuple{Symbol}","page":"Home","title":"KeemenaSubwords.load_tokenizer","text":"Load tokenizer by built-in model name.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.load_tokenizer-Tuple{Tuple{AbstractString, AbstractString}}","page":"Home","title":"KeemenaSubwords.load_tokenizer","text":"Load tokenizer from explicit (vocab_path, merges_path) tuple.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.model_info-Tuple{AbstractSubwordTokenizer}","page":"Home","title":"KeemenaSubwords.model_info","text":"Return model metadata.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.model_info-Tuple{BPETokenizer}","page":"Home","title":"KeemenaSubwords.model_info","text":"Tokenizer metadata.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.model_info-Tuple{ByteBPETokenizer}","page":"Home","title":"KeemenaSubwords.model_info","text":"Tokenizer metadata.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.model_info-Tuple{SentencePieceTokenizer}","page":"Home","title":"KeemenaSubwords.model_info","text":"Tokenizer metadata.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.model_info-Tuple{TiktokenTokenizer}","page":"Home","title":"KeemenaSubwords.model_info","text":"Tokenizer metadata.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.model_info-Tuple{UnigramTokenizer}","page":"Home","title":"KeemenaSubwords.model_info","text":"Tokenizer metadata.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.model_info-Tuple{WordPieceTokenizer}","page":"Home","title":"KeemenaSubwords.model_info","text":"Tokenizer metadata.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.model_path-Tuple{Symbol}","page":"Home","title":"KeemenaSubwords.model_path","text":"Resolve built-in model name to on-disk path.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.normalize_text-Tuple{AbstractString}","page":"Home","title":"KeemenaSubwords.normalize_text","text":"Normalize text using an optional user-provided callable.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.pad_id-Tuple{AbstractSubwordTokenizer}","page":"Home","title":"KeemenaSubwords.pad_id","text":"Padding token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.pad_id-Tuple{BPETokenizer}","page":"Home","title":"KeemenaSubwords.pad_id","text":"Padding token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.pad_id-Tuple{ByteBPETokenizer}","page":"Home","title":"KeemenaSubwords.pad_id","text":"Padding token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.pad_id-Tuple{SentencePieceTokenizer}","page":"Home","title":"KeemenaSubwords.pad_id","text":"Padding token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.pad_id-Tuple{SubwordVocabulary}","page":"Home","title":"KeemenaSubwords.pad_id","text":"Return padding-token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.pad_id-Tuple{TiktokenTokenizer}","page":"Home","title":"KeemenaSubwords.pad_id","text":"Padding token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.pad_id-Tuple{UnigramTokenizer}","page":"Home","title":"KeemenaSubwords.pad_id","text":"Padding token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.pad_id-Tuple{WordPieceTokenizer}","page":"Home","title":"KeemenaSubwords.pad_id","text":"Padding token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.prefetch_models","page":"Home","title":"KeemenaSubwords.prefetch_models","text":"Ensure artifact-backed built-in models are present on disk.\n\nReturns a dictionary of key => is_available.\n\n\n\n\n\n","category":"function"},{"location":"#KeemenaSubwords.recommended_defaults_for_llms-Tuple{}","page":"Home","title":"KeemenaSubwords.recommended_defaults_for_llms","text":"Recommended built-in keys for LLM-oriented default prefetching.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.register_external_model!-Tuple{Symbol, AbstractString}","page":"Home","title":"KeemenaSubwords.register_external_model!","text":"Deprecated alias kept for compatibility. Use register_local_model! instead.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.register_local_model!-Tuple{Symbol, AbstractString}","page":"Home","title":"KeemenaSubwords.register_local_model!","text":"Register a local tokenizer path under a symbolic key and persist it in the cache registry.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.save_tokenizer-Tuple{AbstractSubwordTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.save_tokenizer","text":"Save tokenizer to a canonical on-disk format.\n\nformat=:internal chooses a tokenizer-family specific default:\n\nWordPieceTokenizer -> vocab.txt\nBPETokenizer / ByteBPETokenizer -> vocab.txt + merges.txt\nUnigramTokenizer -> unigram.tsv\nSentencePieceTokenizer -> spm.model\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.special_tokens-Tuple{AbstractSubwordTokenizer}","page":"Home","title":"KeemenaSubwords.special_tokens","text":"Return special token IDs keyed by symbol.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.special_tokens-Tuple{BPETokenizer}","page":"Home","title":"KeemenaSubwords.special_tokens","text":"Special token IDs.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.special_tokens-Tuple{ByteBPETokenizer}","page":"Home","title":"KeemenaSubwords.special_tokens","text":"Special token IDs.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.special_tokens-Tuple{SentencePieceTokenizer}","page":"Home","title":"KeemenaSubwords.special_tokens","text":"Special token IDs.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.special_tokens-Tuple{TiktokenTokenizer}","page":"Home","title":"KeemenaSubwords.special_tokens","text":"Special token IDs.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.special_tokens-Tuple{UnigramTokenizer}","page":"Home","title":"KeemenaSubwords.special_tokens","text":"Special token IDs.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.special_tokens-Tuple{WordPieceTokenizer}","page":"Home","title":"KeemenaSubwords.special_tokens","text":"Special token IDs.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.token_to_id-Tuple{AbstractSubwordTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.token_to_id","text":"Forward token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.token_to_id-Tuple{BPETokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.token_to_id","text":"Forward token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.token_to_id-Tuple{ByteBPETokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.token_to_id","text":"Forward token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.token_to_id-Tuple{SentencePieceTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.token_to_id","text":"Forward token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.token_to_id-Tuple{SubwordVocabulary, AbstractString}","page":"Home","title":"KeemenaSubwords.token_to_id","text":"Map token string to ID, falling back to :unk.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.token_to_id-Tuple{TiktokenTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.token_to_id","text":"Forward token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.token_to_id-Tuple{UnigramTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.token_to_id","text":"Forward token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.token_to_id-Tuple{WordPieceTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.token_to_id","text":"Forward token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.tokenize-Tuple{AbstractSubwordTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.tokenize","text":"Tokenize text into subword pieces.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.tokenize-Tuple{BPETokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.tokenize","text":"Tokenize with classic BPE merges.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.tokenize-Tuple{ByteBPETokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.tokenize","text":"Tokenize text by first mapping bytes to unicode symbols, then applying BPE merges.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.tokenize-Tuple{SentencePieceTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.tokenize","text":"Tokenize text with SentencePiece wrapper behavior.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.tokenize-Tuple{TiktokenTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.tokenize","text":"Tokenize text into b64:<...> token pieces.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.tokenize-Tuple{UnigramTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.tokenize","text":"Tokenize text using deterministic Viterbi segmentation.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.tokenize-Tuple{WordPieceTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.tokenize","text":"Greedy longest-match WordPiece tokenization.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.train_unigram-Tuple{Any}","page":"Home","title":"KeemenaSubwords.train_unigram","text":"High-level Unigram training entry point.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.train_wordpiece-Tuple{Any}","page":"Home","title":"KeemenaSubwords.train_wordpiece","text":"Optional WordPiece training entry point.\n\nThis API is reserved for a later iteration.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.unk_id-Tuple{AbstractSubwordTokenizer}","page":"Home","title":"KeemenaSubwords.unk_id","text":"Unknown token ID.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.unk_id-Tuple{BPETokenizer}","page":"Home","title":"KeemenaSubwords.unk_id","text":"Unknown token ID.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.unk_id-Tuple{ByteBPETokenizer}","page":"Home","title":"KeemenaSubwords.unk_id","text":"Unknown token ID.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.unk_id-Tuple{SentencePieceTokenizer}","page":"Home","title":"KeemenaSubwords.unk_id","text":"Unknown token ID.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.unk_id-Tuple{SubwordVocabulary}","page":"Home","title":"KeemenaSubwords.unk_id","text":"Return unknown-token ID.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.unk_id-Tuple{TiktokenTokenizer}","page":"Home","title":"KeemenaSubwords.unk_id","text":"Unknown token ID.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.unk_id-Tuple{UnigramTokenizer}","page":"Home","title":"KeemenaSubwords.unk_id","text":"Unknown token ID.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.unk_id-Tuple{WordPieceTokenizer}","page":"Home","title":"KeemenaSubwords.unk_id","text":"Unknown token ID.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.vocab_size-Tuple{AbstractSubwordTokenizer}","page":"Home","title":"KeemenaSubwords.vocab_size","text":"Vocabulary size.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.vocab_size-Tuple{BPETokenizer}","page":"Home","title":"KeemenaSubwords.vocab_size","text":"Vocabulary size.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.vocab_size-Tuple{ByteBPETokenizer}","page":"Home","title":"KeemenaSubwords.vocab_size","text":"Vocabulary size.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.vocab_size-Tuple{SentencePieceTokenizer}","page":"Home","title":"KeemenaSubwords.vocab_size","text":"Vocabulary size.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.vocab_size-Tuple{SubwordVocabulary}","page":"Home","title":"KeemenaSubwords.vocab_size","text":"Vocabulary size.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.vocab_size-Tuple{TiktokenTokenizer}","page":"Home","title":"KeemenaSubwords.vocab_size","text":"Vocabulary size.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.vocab_size-Tuple{UnigramTokenizer}","page":"Home","title":"KeemenaSubwords.vocab_size","text":"Vocabulary size.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.vocab_size-Tuple{WordPieceTokenizer}","page":"Home","title":"KeemenaSubwords.vocab_size","text":"Vocabulary size.\n\n\n\n\n\n","category":"method"}]
}
