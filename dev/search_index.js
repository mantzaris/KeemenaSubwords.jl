var documenterSearchIndex = {"docs":
[{"location":"loading_local/#Loading-Tokenizers-From-Local-Paths","page":"Loading Local","title":"Loading Tokenizers From Local Paths","text":"Use explicit format loaders when you know the file layout, or load_tokenizer(path; format=:auto) for detection.","category":"section"},{"location":"loading_local/#GPT-2-/-RoBERTa-style-BPE-(vocab.json-merges.txt)","page":"Loading Local","title":"GPT-2 / RoBERTa style BPE (vocab.json + merges.txt)","text":"tok = load_bpe_gpt2(\"/path/to/vocab.json\", \"/path/to/merges.txt\")","category":"section"},{"location":"loading_local/#OpenAI-encoder-variant-(encoder.json-vocab.bpe)","page":"Loading Local","title":"OpenAI encoder variant (encoder.json + vocab.bpe)","text":"tok = load_bpe_encoder(\"/path/to/encoder.json\", \"/path/to/vocab.bpe\")","category":"section"},{"location":"loading_local/#Classic-BPE-and-Byte-level-BPE-(vocab.txt-merges.txt)","page":"Loading Local","title":"Classic BPE and Byte-level BPE (vocab.txt + merges.txt)","text":"classic = load_bpe(\"/path/to/model_dir\")\nbyte_level = load_bytebpe(\"/path/to/model_dir\")","category":"section"},{"location":"loading_local/#WordPiece-(vocab.txt)","page":"Loading Local","title":"WordPiece (vocab.txt)","text":"wp = load_wordpiece(\"/path/to/vocab.txt\"; continuation_prefix=\"##\")","category":"section"},{"location":"loading_local/#SentencePiece-(.model,-.model.v3,-sentencepiece.bpe.model)","page":"Loading Local","title":"SentencePiece (.model, .model.v3, sentencepiece.bpe.model)","text":"sp_auto = load_sentencepiece(\"/path/to/tokenizer.model\"; kind=:auto)\nsp_uni = load_sentencepiece(\"/path/to/spm.model\"; kind=:unigram)\nsp_bpe = load_sentencepiece(\"/path/to/tokenizer.model.v3\"; kind=:bpe)","category":"section"},{"location":"loading_local/#tiktoken-(*.tiktoken-or-text-tokenizer.model)","page":"Loading Local","title":"tiktoken (*.tiktoken or text tokenizer.model)","text":"tt = load_tiktoken(\"/path/to/o200k_base.tiktoken\")\nllama3_style = load_tiktoken(\"/path/to/tokenizer.model\")","category":"section"},{"location":"loading_local/#Hugging-Face-tokenizer.json","page":"Loading Local","title":"Hugging Face tokenizer.json","text":"hf = load_hf_tokenizer_json(\"/path/to/tokenizer.json\")","category":"section"},{"location":"loading_local/#Generic-auto-detect-override","page":"Loading Local","title":"Generic auto-detect + override","text":"auto_tok = load_tokenizer(\"/path/to/model_dir\")\nforced = load_tokenizer(\"/path/to/tokenizer.model\"; format=:tiktoken)","category":"section"},{"location":"loading_local/#Register-a-local-model-key","page":"Loading Local","title":"Register a local model key","text":"register_local_model!(:my_local_qwen, \"/path/to/model_dir\"; format=:auto, family=:qwen)\nload_tokenizer(:my_local_qwen)\n\nregister_local_model!(\n    :my_local_gpt2,\n    (format=:bpe_gpt2, vocab_json=\"/path/to/vocab.json\", merges_txt=\"/path/to/merges.txt\");\n    family=:local,\n)","category":"section"},{"location":"integration/#Integration-With-KeemenaPreprocessing","page":"Integration","title":"Integration With KeemenaPreprocessing","text":"KeemenaSubwords tokenizers are callable and work with KeemenaPreprocessing's callable tokenizer contract.\n\nusing KeemenaPreprocessing\nusing KeemenaSubwords\n\ntokenizer = load_tokenizer(:core_bpe_en)\n\ncfg = PreprocessConfiguration(tokenizer_name = keemena_callable(tokenizer))\nbundle = preprocess_corpus([\"hello world\", \"hello keemena\"]; config=cfg)\n\n# KeemenaPreprocessing stores callable levels under Symbol(typeof(tokenizer))\nlvl = level_key(tokenizer)\nsubword_corpus = get_corpus(bundle, lvl)","category":"section"},{"location":"formats/#Tokenizer-Formats-and-Required-Files","page":"Formats","title":"Tokenizer Formats and Required Files","text":"detect_tokenizer_format(path) and load_tokenizer(path; format=:auto) use the same detection rules. You can always override detection with format=....\n\nFormat Symbol Accepted Input Required Files Typical Source Recommended Call\n:hf_tokenizer_json file or directory tokenizer.json Hugging Face model repos load_hf_tokenizer_json(\"/path/to/tokenizer.json\")\n:bpe_gpt2 file pair or directory vocab.json + merges.txt GPT-2, RoBERTa, Phi-2, Qwen fallback load_bpe_gpt2(\"/path/to/vocab.json\", \"/path/to/merges.txt\")\n:bpe_encoder file pair or directory encoder.json + vocab.bpe OpenAI GPT-2 blob layout load_bpe_encoder(\"/path/to/encoder.json\", \"/path/to/vocab.bpe\")\n:bpe directory or vocab.txt file vocab.txt + merges.txt Keemena classic BPE fixtures load_bpe(\"/path/to/model_dir\")\n:bytebpe directory or file pair vocab.txt + merges.txt Byte-level custom BPE load_bytebpe(\"/path/to/model_dir\")\n:wordpiece / :wordpiece_vocab file or directory vocab.txt BERT-style WordPiece load_wordpiece(\"/path/to/vocab.txt\")\n:sentencepiece_model file or directory spm.model / spiece.model / tokenizer.model / tokenizer.model.v3 / sentencepiece.bpe.model SentencePiece models (Unigram/BPE) load_sentencepiece(\"/path/to/tokenizer.model\")\n:tiktoken file or directory *.tiktoken or text tokenizer.model OpenAI encodings, LLaMA3-style tokenizer text load_tiktoken(\"/path/to/o200k_base.tiktoken\")\n:unigram file or directory unigram.tsv Internal unigram format load_unigram(\"/path/to/unigram.tsv\")","category":"section"},{"location":"formats/#Detection-Notes","page":"Formats","title":"Detection Notes","text":"Directory preference order starts with tokenizer.json, then GPT-2 pairs, then SentencePiece model names.\n.model files are sniffed:\ntiktoken-like text (<base64> <int>) => :tiktoken\nbinary or SentencePiece-like content => :sentencepiece_model\nIf a path is ambiguous, use explicit override:\n\nload_tokenizer(\"/path/to/tokenizer.model\"; format=:tiktoken)\nload_tokenizer(\"/path/to/tokenizer.model\"; format=:sentencepiece_model)","category":"section"},{"location":"loading/#Loading-Tokenizers","page":"Loading","title":"Loading Tokenizers","text":"Use load_tokenizer for key-based and auto-detected loading, and use explicit constructors when you want strict file contracts.","category":"section"},{"location":"loading/#Built-in-keys","page":"Loading","title":"Built-in keys","text":"using KeemenaSubwords\n\ntok = load_tokenizer(:core_bpe_en)\nqwen = load_tokenizer(:qwen2_5_bpe)","category":"section"},{"location":"loading/#Auto-detected-local-paths","page":"Loading","title":"Auto-detected local paths","text":"load_tokenizer(\"/path/to/model_dir\")\nload_tokenizer(\"/path/to/tokenizer.model\")\nload_tokenizer(\"/path/to/tokenizer.json\")","category":"section"},{"location":"loading/#Force-format-override","page":"Loading","title":"Force format override","text":"load_tokenizer(\"/path/to/tokenizer.model\"; format=:tiktoken)\nload_tokenizer(\"/path/to/tokenizer.model\"; format=:sentencepiece_model)","category":"section"},{"location":"loading/#Explicit-constructors","page":"Loading","title":"Explicit constructors","text":"load_bpe_gpt2(\"/path/to/vocab.json\", \"/path/to/merges.txt\")\nload_bpe_encoder(\"/path/to/encoder.json\", \"/path/to/vocab.bpe\")\nload_wordpiece(\"/path/to/vocab.txt\")\nload_sentencepiece(\"/path/to/tokenizer.model\"; kind=:auto)\nload_tiktoken(\"/path/to/o200k_base.tiktoken\")\nload_hf_tokenizer_json(\"/path/to/tokenizer.json\")\n\nFor complete local path recipes, see loading_local.md.","category":"section"},{"location":"models/#Built-In-Models","page":"Built-In Models","title":"Built-In Models","text":"using KeemenaSubwords\n\navailable_models()\navailable_models(format=:tiktoken)\navailable_models(format=:bpe_gpt2)\navailable_models(format=:hf_tokenizer_json)\navailable_models(family=:qwen)\navailable_models(family=:mistral)\navailable_models(distribution=:artifact_public)\navailable_models(distribution=:installable_gated)\navailable_models(shipped=true)\n\ndescribe_model(:core_bpe_en)\ndescribe_model(:core_wordpiece_en)\ndescribe_model(:core_sentencepiece_unigram_en)\ndescribe_model(:tiktoken_o200k_base)\ndescribe_model(:openai_gpt2_bpe)\ndescribe_model(:bert_base_uncased_wordpiece)\ndescribe_model(:bert_base_multilingual_cased_wordpiece)\ndescribe_model(:t5_small_sentencepiece_unigram)\ndescribe_model(:mistral_v1_sentencepiece)\ndescribe_model(:mistral_v3_sentencepiece)\ndescribe_model(:phi2_bpe)\ndescribe_model(:qwen2_5_bpe)\ndescribe_model(:roberta_base_bpe)\ndescribe_model(:xlm_roberta_base_sentencepiece_bpe)\ndescribe_model(:llama3_8b_tokenizer)\nrecommended_defaults_for_llms()\n\nmodel_path(:core_bpe_en)\n\nThe table below is generated from the same registry used by available_models() and describe_model(...).\n\n<!– KEEMENAMODELSSTART –> Generated from the registry by `tools/syncreadmemodels.jl(excluding:userlocal` entries)._","category":"section"},{"location":"models/#bpe-/-core","page":"Built-In Models","title":"bpe / core","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:core_bpe_en shipped MIT in-repo/core in-repo:core vocab.txt, merges.txt Tiny built-in English classic BPE model (vocab.txt + merges.txt).","category":"section"},{"location":"models/#bpe_gpt2-/-openai","page":"Built-In Models","title":"bpe_gpt2 / openai","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:openai_gpt2_bpe artifact_public MIT openaipublic/gpt-2 openaipublic:gpt-2/encodings/main vocab.json + merges.txt, encoder.json + vocab.bpe OpenAI GPT-2 byte-level BPE assets (encoder.json + vocab.bpe).","category":"section"},{"location":"models/#bpe_gpt2-/-phi","page":"Built-In Models","title":"bpe_gpt2 / phi","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:phi2_bpe artifact_public MIT microsoft/phi-2 huggingface:microsoft/phi-2@810d367871c1d460086d9f82db8696f2e0a0fcd0 vocab.json + merges.txt, encoder.json + vocab.bpe Microsoft Phi-2 GPT2-style tokenizer files (vocab.json + merges.txt).","category":"section"},{"location":"models/#bpe_gpt2-/-roberta","page":"Built-In Models","title":"bpe_gpt2 / roberta","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:roberta_base_bpe artifact_public MIT FacebookAI/roberta-base huggingface:FacebookAI/roberta-base@e2da8e2f811d1448a5b465c236feacd80ffbac7b vocab.json + merges.txt, encoder.json + vocab.bpe RoBERTa-base byte-level BPE tokenizer files (vocab.json + merges.txt).","category":"section"},{"location":"models/#hf_tokenizer_json-/-llama","page":"Built-In Models","title":"hf_tokenizer_json / llama","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:llama3_8b_tokenizer installable_gated Llama-3.1-Community-License meta-llama/Meta-Llama-3-8B-Instruct huggingface:meta-llama/Meta-Llama-3-8B-Instruct@main tokenizer.json (preferred), vocab.json + merges.txt (fallback) Meta Llama 3 8B tokenizer (gated; install with install_model!).","category":"section"},{"location":"models/#hf_tokenizer_json-/-qwen","page":"Built-In Models","title":"hf_tokenizer_json / qwen","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:qwen2_5_bpe artifact_public Apache-2.0 Qwen/Qwen2.5-7B huggingface:Qwen/Qwen2.5-7B@d149729398750b98c0af14eb82c78cfe92750796 tokenizer.json (preferred), vocab.json + merges.txt (fallback) Qwen2.5 BPE tokenizer assets (tokenizer.json with vocab/merges fallback).","category":"section"},{"location":"models/#sentencepiece_model-/-core","page":"Built-In Models","title":"sentencepiece_model / core","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:core_sentencepiece_unigram_en shipped MIT in-repo/core in-repo:core spm.model / tokenizer.model / tokenizer.model.v3 / sentencepiece.bpe.model Tiny built-in SentencePiece Unigram model (.model).","category":"section"},{"location":"models/#sentencepiece_model-/-llama","page":"Built-In Models","title":"sentencepiece_model / llama","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:llama2_tokenizer installable_gated Llama-2-Community-License meta-llama/Llama-2-7b-hf huggingface:meta-llama/Llama-2-7b-hf@main spm.model / tokenizer.model / tokenizer.model.v3 / sentencepiece.bpe.model Meta Llama 2 tokenizer (gated; install with install_model!).","category":"section"},{"location":"models/#sentencepiece_model-/-mistral","page":"Built-In Models","title":"sentencepiece_model / mistral","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:mistral_v1_sentencepiece artifact_public Apache-2.0 mistralai/Mixtral-8x7B-Instruct-v0.1 huggingface:mistralai/Mixtral-8x7B-Instruct-v0.1@eba92302a2861cdc0098cc54bc9f17cb2c47eb61 spm.model / tokenizer.model / tokenizer.model.v3 / sentencepiece.bpe.model Mistral/Mixtral tokenizer.model SentencePiece model.\n:mistral_v3_sentencepiece artifact_public Apache-2.0 mistralai/Mistral-7B-Instruct-v0.3 huggingface:mistralai/Mistral-7B-Instruct-v0.3@c170c708c41dac9275d15a8fff4eca08d52bab71 spm.model / tokenizer.model / tokenizer.model.v3 / sentencepiece.bpe.model Mistral-7B-Instruct-v0.3 tokenizer.model.v3 SentencePiece model.","category":"section"},{"location":"models/#sentencepiece_model-/-t5","page":"Built-In Models","title":"sentencepiece_model / t5","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:t5_small_sentencepiece_unigram artifact_public Apache-2.0 google-t5/t5-small huggingface:google-t5/t5-small@df1b051c49625cf57a3d0d8d3863ed4d13564fe4 spm.model / tokenizer.model / tokenizer.model.v3 / sentencepiece.bpe.model Hugging Face google-t5/t5-small SentencePiece model (Unigram).","category":"section"},{"location":"models/#sentencepiece_model-/-xlm_roberta","page":"Built-In Models","title":"sentencepiece_model / xlm_roberta","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:xlm_roberta_base_sentencepiece_bpe artifact_public MIT FacebookAI/xlm-roberta-base huggingface:FacebookAI/xlm-roberta-base@e73636d4f797dec63c3081bb6ed5c7b0bb3f2089 spm.model / tokenizer.model / tokenizer.model.v3 / sentencepiece.bpe.model XLM-RoBERTa-base sentencepiece.bpe.model file.","category":"section"},{"location":"models/#tiktoken-/-openai","page":"Built-In Models","title":"tiktoken / openai","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:tiktoken_cl100k_base artifact_public MIT openaipublic/encodings openaipublic:encodings/cl100k_base.tiktoken *.tiktoken or tokenizer.model (tiktoken text) OpenAI tiktoken cl100k_base encoding.\n:tiktoken_o200k_base artifact_public MIT openaipublic/encodings openaipublic:encodings/o200k_base.tiktoken *.tiktoken or tokenizer.model (tiktoken text) OpenAI tiktoken o200k_base encoding.\n:tiktoken_p50k_base artifact_public MIT openaipublic/encodings openaipublic:encodings/p50k_base.tiktoken *.tiktoken or tokenizer.model (tiktoken text) OpenAI tiktoken p50k_base encoding.\n:tiktoken_r50k_base artifact_public MIT openaipublic/encodings openaipublic:encodings/r50k_base.tiktoken *.tiktoken or tokenizer.model (tiktoken text) OpenAI tiktoken r50k_base encoding.","category":"section"},{"location":"models/#wordpiece_vocab-/-bert","page":"Built-In Models","title":"wordpiece_vocab / bert","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:bert_base_multilingual_cased_wordpiece artifact_public Apache-2.0 google-bert/bert-base-multilingual-cased huggingface:google-bert/bert-base-multilingual-cased@3f076fdb1ab68d5b2880cb87a0886f315b8146f8 vocab.txt Hugging Face bert-base-multilingual-cased WordPiece vocabulary.\n:bert_base_uncased_wordpiece artifact_public Apache-2.0 bert-base-uncased huggingface:bert-base-uncased@86b5e0934494bd15c9632b12f734a8a67f723594 vocab.txt Hugging Face bert-base-uncased WordPiece vocabulary.","category":"section"},{"location":"models/#wordpiece_vocab-/-core","page":"Built-In Models","title":"wordpiece_vocab / core","text":"Key Distribution License Upstream Repo Upstream Ref Expected Files Description\n:core_wordpiece_en shipped MIT in-repo/core in-repo:core vocab.txt Tiny built-in English WordPiece model.\n\n<!– KEEMENAMODELSEND –>\n\ndescribe_model(key) includes provenance metadata such as license, family, distribution, upstream_repo, upstream_ref, and upstream_files.\n\nBuilt-ins resolve from artifact paths when present, with in-repo fallback model files only for tiny :core_* assets.\n\nprefetch_models(recommended_defaults_for_llms())","category":"section"},{"location":"gated_models/#Installable-Gated-Models","page":"Gated Models","title":"Installable Gated Models","text":"KeemenaSubwords supports gated tokenizers (for example some LLaMA variants) through opt-in installation into your local cache.","category":"section"},{"location":"gated_models/#What-this-does","page":"Gated Models","title":"What this does","text":"install_model!(key; token=...):\n\ndownloads only tokenizer files from upstream with your credentials,\nstores them under your cache (KEEMENA_SUBWORDS_CACHE_DIR override supported),\nregisters them locally so load_tokenizer(:key) works.","category":"section"},{"location":"gated_models/#What-this-does-not-do","page":"Gated Models","title":"What this does not do","text":"No gated tokenizer files are redistributed in this repository.\nNo gated files are published in Artifacts.toml.\nNo silent background downloads happen during load_tokenizer(:key).","category":"section"},{"location":"gated_models/#Install-flow","page":"Gated Models","title":"Install flow","text":"# LLaMA 2\ninstall_model!(:llama2_tokenizer; token=ENV[\"HF_TOKEN\"])\n\n# LLaMA 3 8B\ninstall_model!(:llama3_8b_tokenizer; token=ENV[\"HF_TOKEN\"])\n\n# then load by key\nllama3 = load_tokenizer(:llama3_8b_tokenizer)","category":"section"},{"location":"gated_models/#Discover-gated-keys","page":"Gated Models","title":"Discover gated keys","text":"available_models(distribution=:installable_gated)\ndescribe_model(:llama3_8b_tokenizer)","category":"section"},{"location":"troubleshooting/#Troubleshooting","page":"Troubleshooting","title":"Troubleshooting","text":"","category":"section"},{"location":"troubleshooting/#Auto-detect-picked-the-wrong-format","page":"Troubleshooting","title":"Auto-detect picked the wrong format","text":"Force the format explicitly:\n\nload_tokenizer(\"/path/to/tokenizer.model\"; format=:tiktoken)\nload_tokenizer(\"/path/to/tokenizer.model\"; format=:sentencepiece_model)\n\nUse detection helpers to inspect first:\n\ndetect_tokenizer_format(\"/path/to/model_dir\")\ndetect_tokenizer_files(\"/path/to/model_dir\")","category":"section"},{"location":"troubleshooting/#Missing-merges.txt","page":"Troubleshooting","title":"Missing merges.txt","text":"For GPT-2 style BPE you need both files:\n\nvocab.json + merges.txt\nor encoder.json + vocab.bpe\n\nUse explicit loaders for clearer errors:\n\nload_bpe_gpt2(\"/path/to/vocab.json\", \"/path/to/merges.txt\")\nload_bpe_encoder(\"/path/to/encoder.json\", \"/path/to/vocab.bpe\")","category":"section"},{"location":"troubleshooting/#tokenizer.model-is-not-SentencePiece","page":"Troubleshooting","title":"tokenizer.model is not SentencePiece","text":"Some models (notably LLaMA3-style releases) provide tiktoken text in a file named tokenizer.model.\n\nKeemenaSubwords sniffs .model files:\n\ntiktoken-like text lines => :tiktoken\nbinary / SentencePiece-like payload => :sentencepiece_model\n\nIf needed, override manually:\n\nload_tokenizer(\"/path/to/tokenizer.model\"; format=:tiktoken)","category":"section"},{"location":"troubleshooting/#Gated-model-key-fails-to-load","page":"Troubleshooting","title":"Gated model key fails to load","text":"If load_tokenizer(:llama3_8b_tokenizer) says not installed, install first:\n\ninstall_model!(:llama3_8b_tokenizer; token=ENV[\"HF_TOKEN\"])\n\nYou must have accepted upstream license terms and have valid access.","category":"section"},{"location":"#KeemenaSubwords.jl","page":"Home","title":"KeemenaSubwords.jl","text":"Downstream of KeemenaPreprocessing.jl.\n\nKeemenaSubwords provides Julia-native loaders and tokenization primitives for:\n\nclassic BPE,\nbyte-level BPE,\nWordPiece,\nSentencePiece,\ntiktoken,\nHugging Face tokenizer.json.","category":"section"},{"location":"#Quick-Start","page":"Home","title":"Quick Start","text":"using KeemenaSubwords\n\ntok = load_tokenizer(:core_bpe_en)\npieces = tokenize(tok, \"hello world\")\nids = encode(tok, \"hello world\"; add_special_tokens=true)\ntext = decode(tok, ids)","category":"section"},{"location":"#Model-Discovery","page":"Home","title":"Model Discovery","text":"available_models()\navailable_models(distribution=:artifact_public)\navailable_models(distribution=:installable_gated)\ndescribe_model(:qwen2_5_bpe)\nrecommended_defaults_for_llms()","category":"section"},{"location":"#Key-Workflows","page":"Home","title":"Key Workflows","text":"# local path auto-detection\nload_tokenizer(\"/path/to/model_dir\")\n\n# explicit loaders\nload_bpe_gpt2(\"/path/to/vocab.json\", \"/path/to/merges.txt\")\nload_sentencepiece(\"/path/to/tokenizer.model\")\nload_tiktoken(\"/path/to/tokenizer.model\")\n\n# gated install flow\ninstall_model!(:llama3_8b_tokenizer; token=ENV[\"HF_TOKEN\"])","category":"section"},{"location":"#Documentation-Map","page":"Home","title":"Documentation Map","text":"Built-in model inventory: models.md\nFormat contracts: formats.md\nLocal path recipes: loading_local.md\nLLM cookbook: llm_cookbook.md\nInstallable gated models: gated_models.md\nTroubleshooting: troubleshooting.md","category":"section"},{"location":"#KeemenaPreprocessing-Integration","page":"Home","title":"KeemenaPreprocessing Integration","text":"using KeemenaPreprocessing\nusing KeemenaSubwords\n\ntok = load_tokenizer(:core_bpe_en)\ncfg = PreprocessConfiguration(tokenizer_name = keemena_callable(tok))\nbundle = preprocess_corpus([\"hello world\"]; config=cfg)","category":"section"},{"location":"#API","page":"Home","title":"API","text":"","category":"section"},{"location":"#KeemenaSubwords.AbstractSubwordTokenizer","page":"Home","title":"KeemenaSubwords.AbstractSubwordTokenizer","text":"Abstract parent type for all subword tokenizers.\n\nTokenizers are callable and support: tokenizer(text::AbstractString) -> Vector{String}.\n\n\n\n\n\n","category":"type"},{"location":"#KeemenaSubwords.SubwordVocabulary","page":"Home","title":"KeemenaSubwords.SubwordVocabulary","text":"Vocabulary container with forward/reverse lookup and special token IDs.\n\nIDs are 1-based.\n\n\n\n\n\n","category":"type"},{"location":"#KeemenaSubwords.TokenizerMetadata","page":"Home","title":"KeemenaSubwords.TokenizerMetadata","text":"Common metadata for tokenizer instances.\n\n\n\n\n\n","category":"type"},{"location":"#KeemenaSubwords.available_models-Tuple{}","page":"Home","title":"KeemenaSubwords.available_models","text":"List available built-in model names.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.bos_id-Tuple{AbstractSubwordTokenizer}","page":"Home","title":"KeemenaSubwords.bos_id","text":"BOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.bos_id-Tuple{BPETokenizer}","page":"Home","title":"KeemenaSubwords.bos_id","text":"BOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.bos_id-Tuple{ByteBPETokenizer}","page":"Home","title":"KeemenaSubwords.bos_id","text":"BOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.bos_id-Tuple{SentencePieceTokenizer}","page":"Home","title":"KeemenaSubwords.bos_id","text":"BOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.bos_id-Tuple{SubwordVocabulary}","page":"Home","title":"KeemenaSubwords.bos_id","text":"Return beginning-of-sequence token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.bos_id-Tuple{TiktokenTokenizer}","page":"Home","title":"KeemenaSubwords.bos_id","text":"BOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.bos_id-Tuple{UnigramTokenizer}","page":"Home","title":"KeemenaSubwords.bos_id","text":"BOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.bos_id-Tuple{WordPieceTokenizer}","page":"Home","title":"KeemenaSubwords.bos_id","text":"BOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.decode-Tuple{AbstractSubwordTokenizer, AbstractVector{Int64}}","page":"Home","title":"KeemenaSubwords.decode","text":"Decode token IDs into text.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.decode-Tuple{BPETokenizer, AbstractVector{Int64}}","page":"Home","title":"KeemenaSubwords.decode","text":"Decode token IDs to text.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.decode-Tuple{ByteBPETokenizer, AbstractVector{Int64}}","page":"Home","title":"KeemenaSubwords.decode","text":"Decode byte-level BPE IDs back to text.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.decode-Tuple{SentencePieceTokenizer, AbstractVector{Int64}}","page":"Home","title":"KeemenaSubwords.decode","text":"Decode SentencePiece IDs back to text.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.decode-Tuple{TiktokenTokenizer, AbstractVector{Int64}}","page":"Home","title":"KeemenaSubwords.decode","text":"Decode tiktoken rank IDs to text.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.decode-Tuple{UnigramTokenizer, AbstractVector{Int64}}","page":"Home","title":"KeemenaSubwords.decode","text":"Decode unigram token IDs back to text.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.decode-Tuple{WordPieceTokenizer, AbstractVector{Int64}}","page":"Home","title":"KeemenaSubwords.decode","text":"Decode WordPiece token IDs back into text.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.describe_model-Tuple{Symbol}","page":"Home","title":"KeemenaSubwords.describe_model","text":"Describe a built-in model.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.detect_tokenizer_files-Tuple{AbstractString}","page":"Home","title":"KeemenaSubwords.detect_tokenizer_files","text":"Inspect a tokenizer directory and return detected candidate files.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.detect_tokenizer_format-Tuple{AbstractString}","page":"Home","title":"KeemenaSubwords.detect_tokenizer_format","text":"Detect tokenizer format from a local file or directory.\n\nReturns one of symbols such as :hf_tokenizer_json, :bpe_gpt2, :bpe_encoder, :sentencepiece_model, :tiktoken, :wordpiece, :bpe, or :unigram.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.download_hf_files-Tuple{AbstractString, AbstractVector{<:AbstractString}}","page":"Home","title":"KeemenaSubwords.download_hf_files","text":"Download selected files from a Hugging Face repository revision into cache.\n\nThis helper is opt-in and useful for user-managed / gated tokenizers.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.encode-Tuple{AbstractSubwordTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.encode","text":"Encode text into token IDs.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.encode-Tuple{BPETokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.encode","text":"Encode text to token IDs.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.encode-Tuple{ByteBPETokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.encode","text":"Encode text to byte-level BPE IDs.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.encode-Tuple{SentencePieceTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.encode","text":"Encode text to SentencePiece IDs.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.encode-Tuple{TiktokenTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.encode","text":"Encode text into tiktoken rank IDs (1-based in this package).\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.encode-Tuple{UnigramTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.encode","text":"Encode text to unigram token IDs.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.encode-Tuple{WordPieceTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.encode","text":"Encode text to WordPiece token IDs.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.eos_id-Tuple{AbstractSubwordTokenizer}","page":"Home","title":"KeemenaSubwords.eos_id","text":"EOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.eos_id-Tuple{BPETokenizer}","page":"Home","title":"KeemenaSubwords.eos_id","text":"EOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.eos_id-Tuple{ByteBPETokenizer}","page":"Home","title":"KeemenaSubwords.eos_id","text":"EOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.eos_id-Tuple{SentencePieceTokenizer}","page":"Home","title":"KeemenaSubwords.eos_id","text":"EOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.eos_id-Tuple{SubwordVocabulary}","page":"Home","title":"KeemenaSubwords.eos_id","text":"Return end-of-sequence token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.eos_id-Tuple{TiktokenTokenizer}","page":"Home","title":"KeemenaSubwords.eos_id","text":"EOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.eos_id-Tuple{UnigramTokenizer}","page":"Home","title":"KeemenaSubwords.eos_id","text":"EOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.eos_id-Tuple{WordPieceTokenizer}","page":"Home","title":"KeemenaSubwords.eos_id","text":"EOS token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.export_tokenizer-Tuple{AbstractSubwordTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.export_tokenizer","text":"Export tokenizer to external formats.\n\nSupported format values:\n\n:internal\n:bpe / :bpe_gpt2\n:wordpiece_vocab\n:unigram_tsv\n:sentencepiece_model\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.id_to_token-Tuple{AbstractSubwordTokenizer, Int64}","page":"Home","title":"KeemenaSubwords.id_to_token","text":"Reverse token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.id_to_token-Tuple{BPETokenizer, Int64}","page":"Home","title":"KeemenaSubwords.id_to_token","text":"Reverse token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.id_to_token-Tuple{ByteBPETokenizer, Int64}","page":"Home","title":"KeemenaSubwords.id_to_token","text":"Reverse token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.id_to_token-Tuple{SentencePieceTokenizer, Int64}","page":"Home","title":"KeemenaSubwords.id_to_token","text":"Reverse token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.id_to_token-Tuple{SubwordVocabulary, Int64}","page":"Home","title":"KeemenaSubwords.id_to_token","text":"Map ID to token string.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.id_to_token-Tuple{TiktokenTokenizer, Int64}","page":"Home","title":"KeemenaSubwords.id_to_token","text":"Reverse token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.id_to_token-Tuple{UnigramTokenizer, Int64}","page":"Home","title":"KeemenaSubwords.id_to_token","text":"Reverse token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.id_to_token-Tuple{WordPieceTokenizer, Int64}","page":"Home","title":"KeemenaSubwords.id_to_token","text":"Reverse token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.install_model!-Tuple{Symbol}","page":"Home","title":"KeemenaSubwords.install_model!","text":"Install an installable-gated tokenizer into the user cache and register it by key.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.keemena_callable-Tuple{AbstractSubwordTokenizer}","page":"Home","title":"KeemenaSubwords.keemena_callable","text":"Return a function compatible with KeemenaPreprocessing's callable tokenizer contract.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.level_key-Tuple{AbstractSubwordTokenizer}","page":"Home","title":"KeemenaSubwords.level_key","text":"Level key used by KeemenaPreprocessing for callable tokenizers.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.load_bpe_encoder-Tuple{AbstractString, AbstractString}","page":"Home","title":"KeemenaSubwords.load_bpe_encoder","text":"Load GPT-2 encoder variant from encoder.json + vocab.bpe.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.load_bpe_gpt2-Tuple{AbstractString, AbstractString}","page":"Home","title":"KeemenaSubwords.load_bpe_gpt2","text":"Load GPT-2 / RoBERTa style BPE from vocab.json + merges.txt.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.load_hf_tokenizer_json-Tuple{AbstractString}","page":"Home","title":"KeemenaSubwords.load_hf_tokenizer_json","text":"Load a Hugging Face tokenizer.json tokenizer in pure Julia.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.load_sentencepiece-Tuple{AbstractString}","page":"Home","title":"KeemenaSubwords.load_sentencepiece","text":"Load a SentencePiece .model file.\n\nSupported model file format in this package is a lightweight text form:\n\nkey/value lines (type=unigram|bpe, whitespace_marker=▁, unk_token=<unk>)\npiece rows: piece<TAB>token<TAB>score[<TAB>special_symbol]\nbpe merge rows (for type=bpe): merge<TAB>left<TAB>right\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.load_tiktoken-Tuple{AbstractString}","page":"Home","title":"KeemenaSubwords.load_tiktoken","text":"Load a tiktoken encoding file (*.tiktoken).\n\nThe expected format is line-based: <base64_token_bytes><space><rank> where ranks are non-negative integers.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.load_tokenizer-Tuple{AbstractString}","page":"Home","title":"KeemenaSubwords.load_tokenizer","text":"Load tokenizer from file system path.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.load_tokenizer-Tuple{NamedTuple}","page":"Home","title":"KeemenaSubwords.load_tokenizer","text":"Load tokenizer from a named specification.\n\nExamples:\n\n(format=:wordpiece, path=\"/.../vocab.txt\")\n(format=:bpe_gpt2, vocab=\"/.../vocab.txt\", merges=\"/.../merges.txt\")\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.load_tokenizer-Tuple{Symbol}","page":"Home","title":"KeemenaSubwords.load_tokenizer","text":"Load tokenizer by built-in model name.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.load_tokenizer-Tuple{Tuple{AbstractString, AbstractString}}","page":"Home","title":"KeemenaSubwords.load_tokenizer","text":"Load tokenizer from explicit (vocab_path, merges_path) tuple.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.load_wordpiece-Tuple{AbstractString}","page":"Home","title":"KeemenaSubwords.load_wordpiece","text":"Load a WordPiece tokenizer from a vocab file path or a directory containing vocab.txt.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.model_info-Tuple{AbstractSubwordTokenizer}","page":"Home","title":"KeemenaSubwords.model_info","text":"Return model metadata.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.model_info-Tuple{BPETokenizer}","page":"Home","title":"KeemenaSubwords.model_info","text":"Tokenizer metadata.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.model_info-Tuple{ByteBPETokenizer}","page":"Home","title":"KeemenaSubwords.model_info","text":"Tokenizer metadata.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.model_info-Tuple{SentencePieceTokenizer}","page":"Home","title":"KeemenaSubwords.model_info","text":"Tokenizer metadata.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.model_info-Tuple{TiktokenTokenizer}","page":"Home","title":"KeemenaSubwords.model_info","text":"Tokenizer metadata.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.model_info-Tuple{UnigramTokenizer}","page":"Home","title":"KeemenaSubwords.model_info","text":"Tokenizer metadata.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.model_info-Tuple{WordPieceTokenizer}","page":"Home","title":"KeemenaSubwords.model_info","text":"Tokenizer metadata.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.model_path-Tuple{Symbol}","page":"Home","title":"KeemenaSubwords.model_path","text":"Resolve built-in model name to on-disk path.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.normalize_text-Tuple{AbstractString}","page":"Home","title":"KeemenaSubwords.normalize_text","text":"Normalize text using an optional user-provided callable.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.pad_id-Tuple{AbstractSubwordTokenizer}","page":"Home","title":"KeemenaSubwords.pad_id","text":"Padding token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.pad_id-Tuple{BPETokenizer}","page":"Home","title":"KeemenaSubwords.pad_id","text":"Padding token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.pad_id-Tuple{ByteBPETokenizer}","page":"Home","title":"KeemenaSubwords.pad_id","text":"Padding token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.pad_id-Tuple{SentencePieceTokenizer}","page":"Home","title":"KeemenaSubwords.pad_id","text":"Padding token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.pad_id-Tuple{SubwordVocabulary}","page":"Home","title":"KeemenaSubwords.pad_id","text":"Return padding-token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.pad_id-Tuple{TiktokenTokenizer}","page":"Home","title":"KeemenaSubwords.pad_id","text":"Padding token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.pad_id-Tuple{UnigramTokenizer}","page":"Home","title":"KeemenaSubwords.pad_id","text":"Padding token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.pad_id-Tuple{WordPieceTokenizer}","page":"Home","title":"KeemenaSubwords.pad_id","text":"Padding token ID if available.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.prefetch_models","page":"Home","title":"KeemenaSubwords.prefetch_models","text":"Ensure artifact-backed built-in models are present on disk.\n\nReturns a dictionary of key => is_available.\n\n\n\n\n\n","category":"function"},{"location":"#KeemenaSubwords.recommended_defaults_for_llms-Tuple{}","page":"Home","title":"KeemenaSubwords.recommended_defaults_for_llms","text":"Recommended built-in keys for LLM-oriented default prefetching.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.register_external_model!-Tuple{Symbol, AbstractString}","page":"Home","title":"KeemenaSubwords.register_external_model!","text":"Deprecated alias kept for compatibility. Use register_local_model! instead.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.register_local_model!-Tuple{Symbol, AbstractString}","page":"Home","title":"KeemenaSubwords.register_local_model!","text":"Register a local tokenizer path under a symbolic key and persist it in the cache registry.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.register_local_model!-Tuple{Symbol, NamedTuple}","page":"Home","title":"KeemenaSubwords.register_local_model!","text":"Register local model files by explicit specification.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.save_tokenizer-Tuple{AbstractSubwordTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.save_tokenizer","text":"Save tokenizer to a canonical on-disk format.\n\nformat=:internal chooses a tokenizer-family specific default:\n\nWordPieceTokenizer -> vocab.txt\nBPETokenizer / ByteBPETokenizer -> vocab.txt + merges.txt\nUnigramTokenizer -> unigram.tsv\nSentencePieceTokenizer -> spm.model\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.special_tokens-Tuple{AbstractSubwordTokenizer}","page":"Home","title":"KeemenaSubwords.special_tokens","text":"Return special token IDs keyed by symbol.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.special_tokens-Tuple{BPETokenizer}","page":"Home","title":"KeemenaSubwords.special_tokens","text":"Special token IDs.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.special_tokens-Tuple{ByteBPETokenizer}","page":"Home","title":"KeemenaSubwords.special_tokens","text":"Special token IDs.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.special_tokens-Tuple{SentencePieceTokenizer}","page":"Home","title":"KeemenaSubwords.special_tokens","text":"Special token IDs.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.special_tokens-Tuple{TiktokenTokenizer}","page":"Home","title":"KeemenaSubwords.special_tokens","text":"Special token IDs.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.special_tokens-Tuple{UnigramTokenizer}","page":"Home","title":"KeemenaSubwords.special_tokens","text":"Special token IDs.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.special_tokens-Tuple{WordPieceTokenizer}","page":"Home","title":"KeemenaSubwords.special_tokens","text":"Special token IDs.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.token_to_id-Tuple{AbstractSubwordTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.token_to_id","text":"Forward token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.token_to_id-Tuple{BPETokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.token_to_id","text":"Forward token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.token_to_id-Tuple{ByteBPETokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.token_to_id","text":"Forward token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.token_to_id-Tuple{SentencePieceTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.token_to_id","text":"Forward token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.token_to_id-Tuple{SubwordVocabulary, AbstractString}","page":"Home","title":"KeemenaSubwords.token_to_id","text":"Map token string to ID, falling back to :unk.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.token_to_id-Tuple{TiktokenTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.token_to_id","text":"Forward token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.token_to_id-Tuple{UnigramTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.token_to_id","text":"Forward token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.token_to_id-Tuple{WordPieceTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.token_to_id","text":"Forward token lookup.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.tokenize-Tuple{AbstractSubwordTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.tokenize","text":"Tokenize text into subword pieces.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.tokenize-Tuple{BPETokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.tokenize","text":"Tokenize with classic BPE merges.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.tokenize-Tuple{ByteBPETokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.tokenize","text":"Tokenize text by first mapping bytes to unicode symbols, then applying BPE merges.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.tokenize-Tuple{SentencePieceTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.tokenize","text":"Tokenize text with SentencePiece wrapper behavior.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.tokenize-Tuple{TiktokenTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.tokenize","text":"Tokenize text into b64:<...> token pieces.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.tokenize-Tuple{UnigramTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.tokenize","text":"Tokenize text using deterministic Viterbi segmentation.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.tokenize-Tuple{WordPieceTokenizer, AbstractString}","page":"Home","title":"KeemenaSubwords.tokenize","text":"Greedy longest-match WordPiece tokenization.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.train_unigram-Tuple{Any}","page":"Home","title":"KeemenaSubwords.train_unigram","text":"High-level Unigram training entry point.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.train_wordpiece-Tuple{Any}","page":"Home","title":"KeemenaSubwords.train_wordpiece","text":"Optional WordPiece training entry point.\n\nThis API is reserved for a later iteration.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.unk_id-Tuple{AbstractSubwordTokenizer}","page":"Home","title":"KeemenaSubwords.unk_id","text":"Unknown token ID.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.unk_id-Tuple{BPETokenizer}","page":"Home","title":"KeemenaSubwords.unk_id","text":"Unknown token ID.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.unk_id-Tuple{ByteBPETokenizer}","page":"Home","title":"KeemenaSubwords.unk_id","text":"Unknown token ID.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.unk_id-Tuple{SentencePieceTokenizer}","page":"Home","title":"KeemenaSubwords.unk_id","text":"Unknown token ID.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.unk_id-Tuple{SubwordVocabulary}","page":"Home","title":"KeemenaSubwords.unk_id","text":"Return unknown-token ID.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.unk_id-Tuple{TiktokenTokenizer}","page":"Home","title":"KeemenaSubwords.unk_id","text":"Unknown token ID.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.unk_id-Tuple{UnigramTokenizer}","page":"Home","title":"KeemenaSubwords.unk_id","text":"Unknown token ID.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.unk_id-Tuple{WordPieceTokenizer}","page":"Home","title":"KeemenaSubwords.unk_id","text":"Unknown token ID.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.vocab_size-Tuple{AbstractSubwordTokenizer}","page":"Home","title":"KeemenaSubwords.vocab_size","text":"Vocabulary size.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.vocab_size-Tuple{BPETokenizer}","page":"Home","title":"KeemenaSubwords.vocab_size","text":"Vocabulary size.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.vocab_size-Tuple{ByteBPETokenizer}","page":"Home","title":"KeemenaSubwords.vocab_size","text":"Vocabulary size.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.vocab_size-Tuple{SentencePieceTokenizer}","page":"Home","title":"KeemenaSubwords.vocab_size","text":"Vocabulary size.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.vocab_size-Tuple{SubwordVocabulary}","page":"Home","title":"KeemenaSubwords.vocab_size","text":"Vocabulary size.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.vocab_size-Tuple{TiktokenTokenizer}","page":"Home","title":"KeemenaSubwords.vocab_size","text":"Vocabulary size.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.vocab_size-Tuple{UnigramTokenizer}","page":"Home","title":"KeemenaSubwords.vocab_size","text":"Vocabulary size.\n\n\n\n\n\n","category":"method"},{"location":"#KeemenaSubwords.vocab_size-Tuple{WordPieceTokenizer}","page":"Home","title":"KeemenaSubwords.vocab_size","text":"Vocabulary size.\n\n\n\n\n\n","category":"method"},{"location":"llm_cookbook/#LLM-Cookbook","page":"LLM Cookbook","title":"LLM Cookbook","text":"","category":"section"},{"location":"llm_cookbook/#OpenAI-tiktoken-encodings","page":"LLM Cookbook","title":"OpenAI tiktoken encodings","text":"prefetch_models([:tiktoken_cl100k_base, :tiktoken_o200k_base])\ntt = load_tokenizer(:tiktoken_cl100k_base)\nencode(tt, \"hello world\")","category":"section"},{"location":"llm_cookbook/#Mistral-SentencePiece","page":"LLM Cookbook","title":"Mistral SentencePiece","text":"prefetch_models([:mistral_v3_sentencepiece])\nmistral = load_tokenizer(:mistral_v3_sentencepiece)","category":"section"},{"location":"llm_cookbook/#Qwen-tokenizer.json-first-loading","page":"LLM Cookbook","title":"Qwen tokenizer.json-first loading","text":"prefetch_models([:qwen2_5_bpe])\nqwen = load_tokenizer(:qwen2_5_bpe)","category":"section"},{"location":"llm_cookbook/#LLaMA-workflow-A:-install-(gated)","page":"LLM Cookbook","title":"LLaMA workflow A: install (gated)","text":"install_model!(:llama3_8b_tokenizer; token=ENV[\"HF_TOKEN\"])\nllama = load_tokenizer(:llama3_8b_tokenizer)","category":"section"},{"location":"llm_cookbook/#LLaMA-workflow-B:-manual-local-path","page":"LLM Cookbook","title":"LLaMA workflow B: manual local path","text":"# SentencePiece-style\nllama2 = load_tokenizer(\"/path/to/tokenizer.model\"; format=:sentencepiece_model)\n\n# LLaMA3-style tokenizer.model with tiktoken text\nllama3 = load_tokenizer(\"/path/to/tokenizer.model\"; format=:tiktoken)","category":"section"},{"location":"llm_cookbook/#Pick-practical-defaults","page":"LLM Cookbook","title":"Pick practical defaults","text":"for key in recommended_defaults_for_llms()\n    println(key)\nend","category":"section"}]
}
