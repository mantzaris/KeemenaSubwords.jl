<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API Reference · KeemenaSubwords.jl</title><meta name="title" content="API Reference · KeemenaSubwords.jl"/><meta property="og:title" content="API Reference · KeemenaSubwords.jl"/><meta property="twitter:title" content="API Reference · KeemenaSubwords.jl"/><meta name="description" content="Documentation for KeemenaSubwords.jl."/><meta property="og:description" content="Documentation for KeemenaSubwords.jl."/><meta property="twitter:description" content="Documentation for KeemenaSubwords.jl."/><meta property="og:url" content="https://mantzaris.github.io/KeemenaSubwords.jl/api/"/><meta property="twitter:url" content="https://mantzaris.github.io/KeemenaSubwords.jl/api/"/><link rel="canonical" href="https://mantzaris.github.io/KeemenaSubwords.jl/api/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">KeemenaSubwords.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../integration/">Integration</a></li><li><a class="tocitem" href="../loading/">Loading</a></li><li><a class="tocitem" href="../formats/">Formats</a></li><li><a class="tocitem" href="../loading_local/">Loading Local</a></li><li><a class="tocitem" href="../llm_cookbook/">LLM Cookbook</a></li><li><a class="tocitem" href="../gated_models/">Gated Models</a></li><li><a class="tocitem" href="../troubleshooting/">Troubleshooting</a></li><li><a class="tocitem" href="../models/">Built-In Models</a></li><li class="is-active"><a class="tocitem" href>API Reference</a><ul class="internal"><li><a class="tocitem" href="#Explicit-Loader-APIs"><span>Explicit Loader APIs</span></a></li><li><a class="tocitem" href="#Registry-and-Installation-APIs"><span>Registry and Installation APIs</span></a></li><li><a class="tocitem" href="#Full-Exported-API"><span>Full Exported API</span></a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>API Reference</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>API Reference</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/mantzaris/KeemenaSubwords.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/main/docs/src/api.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="API-Reference"><a class="docs-heading-anchor" href="#API-Reference">API Reference</a><a id="API-Reference-1"></a><a class="docs-heading-anchor-permalink" href="#API-Reference" title="Permalink"></a></h1><h2 id="Explicit-Loader-APIs"><a class="docs-heading-anchor" href="#Explicit-Loader-APIs">Explicit Loader APIs</a><a id="Explicit-Loader-APIs-1"></a><a class="docs-heading-anchor-permalink" href="#Explicit-Loader-APIs" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="KeemenaSubwords.load_bpe"><a class="docstring-binding" href="#KeemenaSubwords.load_bpe"><code>KeemenaSubwords.load_bpe</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>Load a BPE tokenizer from either a directory (<code>vocab.txt</code> + <code>merges.txt</code>) or a vocab file path.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bpe.jl#L9-L11">source</a></section><section><div><p>Load a BPE tokenizer from explicit vocab + merges paths.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bpe.jl#L26-L28">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.load_bytebpe"><a class="docstring-binding" href="#KeemenaSubwords.load_bytebpe"><code>KeemenaSubwords.load_bytebpe</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>Load a byte-level BPE tokenizer from a directory (<code>vocab.txt</code> + <code>merges.txt</code>) or vocab path.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bytebpe.jl#L8-L10">source</a></section><section><div><p>Load a byte-level BPE tokenizer from explicit vocab + merges paths.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bytebpe.jl#L25-L27">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.load_bpe_gpt2"><a class="docstring-binding" href="#KeemenaSubwords.load_bpe_gpt2"><code>KeemenaSubwords.load_bpe_gpt2</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>Load GPT-2 / RoBERTa style BPE from <code>vocab.json</code> + <code>merges.txt</code>.</p><p>Example: <code>load_bpe_gpt2(&quot;/path/to/vocab.json&quot;, &quot;/path/to/merges.txt&quot;)</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/io.jl#L896-L901">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.load_bpe_encoder"><a class="docstring-binding" href="#KeemenaSubwords.load_bpe_encoder"><code>KeemenaSubwords.load_bpe_encoder</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>Load GPT-2 encoder variant from <code>encoder.json</code> + <code>vocab.bpe</code>.</p><p>Example: <code>load_bpe_encoder(&quot;/path/to/encoder.json&quot;, &quot;/path/to/vocab.bpe&quot;)</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/io.jl#L948-L953">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.load_unigram"><a class="docstring-binding" href="#KeemenaSubwords.load_unigram"><code>KeemenaSubwords.load_unigram</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>Load a Unigram tokenizer from <code>unigram.tsv</code> (file or directory).</p><p>Expected format (tab-separated): <code>token&lt;TAB&gt;score[&lt;TAB&gt;special_symbol]</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/unigram.jl#L9-L14">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.load_wordpiece"><a class="docstring-binding" href="#KeemenaSubwords.load_wordpiece"><code>KeemenaSubwords.load_wordpiece</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>Load a WordPiece tokenizer from a vocab file path or a directory containing <code>vocab.txt</code>.</p><p>Examples:</p><ul><li><code>load_wordpiece(&quot;/path/to/vocab.txt&quot;)</code></li><li><code>load_wordpiece(&quot;/path/to/model_dir&quot;)</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/wordpiece.jl#L9-L15">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.load_sentencepiece"><a class="docstring-binding" href="#KeemenaSubwords.load_sentencepiece"><code>KeemenaSubwords.load_sentencepiece</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>Load a SentencePiece <code>.model</code> file.</p><p>Supported inputs:</p><ul><li>standard SentencePiece binary protobuf <code>.model</code>/<code>.model.v3</code> payloads</li><li>Keemena text-exported model files:<ul><li>key/value lines (<code>type=unigram|bpe</code>, <code>whitespace_marker=▁</code>, <code>unk_token=&lt;unk&gt;</code>)</li><li>piece rows: <code>piece&lt;TAB&gt;token&lt;TAB&gt;score[&lt;TAB&gt;special_symbol]</code></li><li>bpe merge rows (for <code>type=bpe</code>): <code>merge&lt;TAB&gt;left&lt;TAB&gt;right</code></li></ul></li></ul><p>Examples:</p><ul><li><code>load_sentencepiece(&quot;/path/to/tokenizer.model&quot;; kind=:auto)</code></li><li><code>load_sentencepiece(&quot;/path/to/tokenizer.model.v3&quot;; kind=:bpe)</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/sentencepiece.jl#L7-L20">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.load_tiktoken"><a class="docstring-binding" href="#KeemenaSubwords.load_tiktoken"><code>KeemenaSubwords.load_tiktoken</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>Load a tiktoken encoding file (<code>*.tiktoken</code>).</p><p>The expected format is line-based: <code>&lt;base64_token_bytes&gt;&lt;space&gt;&lt;rank&gt;</code> where ranks are non-negative integers.</p><p>Examples:</p><ul><li><code>load_tiktoken(&quot;/path/to/o200k_base.tiktoken&quot;)</code></li><li><code>load_tiktoken(&quot;/path/to/tokenizer.model&quot;)</code> (when file contains tiktoken text lines)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/tiktoken.jl#L11-L21">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.load_hf_tokenizer_json"><a class="docstring-binding" href="#KeemenaSubwords.load_hf_tokenizer_json"><code>KeemenaSubwords.load_hf_tokenizer_json</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>Load a Hugging Face <code>tokenizer.json</code> tokenizer in pure Julia.</p><p>Expected files:</p><ul><li><code>tokenizer.json</code> directly, or</li><li>a directory containing <code>tokenizer.json</code>.</li></ul><p>Examples:</p><ul><li><code>load_hf_tokenizer_json(&quot;/path/to/tokenizer.json&quot;)</code></li><li><code>load_hf_tokenizer_json(&quot;/path/to/model_dir&quot;)</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/huggingface_json/hf_json_loader.jl#L1-L11">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.load_tokenizer"><a class="docstring-binding" href="#KeemenaSubwords.load_tokenizer"><code>KeemenaSubwords.load_tokenizer</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>Load tokenizer by built-in model name.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/io.jl#L1-L3">source</a></section><section><div><p>Load tokenizer from file system path.</p><p>Common <code>format</code> contracts:</p><ul><li><code>:hf_tokenizer_json</code> -&gt; <code>tokenizer.json</code></li><li><code>:bpe_gpt2</code> -&gt; <code>vocab.json</code> + <code>merges.txt</code></li><li><code>:bpe_encoder</code> -&gt; <code>encoder.json</code> + <code>vocab.bpe</code></li><li><code>:wordpiece</code> / <code>:wordpiece_vocab</code> -&gt; <code>vocab.txt</code></li><li><code>:sentencepiece_model</code> -&gt; <code>*.model</code> / <code>*.model.v3</code> / <code>sentencepiece.bpe.model</code></li><li><code>:tiktoken</code> -&gt; <code>*.tiktoken</code> or tiktoken-text <code>tokenizer.model</code></li></ul><p>Examples:</p><ul><li><code>load_tokenizer(&quot;/path/to/model_dir&quot;)</code></li><li><code>load_tokenizer(&quot;/path/to/tokenizer.model&quot;; format=:tiktoken)</code></li><li><code>load_tokenizer(&quot;/path/to/tokenizer.json&quot;; format=:hf_tokenizer_json)</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/io.jl#L24-L39">source</a></section><section><div><p>Load tokenizer from explicit <code>(vocab_path, merges_path)</code> tuple.</p><p>This tuple form is for classic BPE/byte-level BPE (<code>vocab.txt</code> + <code>merges.txt</code>) or explicit JSON-pair loaders (<code>vocab.json</code> + <code>merges.txt</code>, <code>encoder.json</code> + <code>vocab.bpe</code>) when accompanied by <code>format</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/io.jl#L90-L96">source</a></section><section><div><p>Load tokenizer from a named specification.</p><p>Examples:</p><ul><li><code>(format=:wordpiece, path=&quot;/.../vocab.txt&quot;)</code></li><li><code>(format=:hf_tokenizer_json, path=&quot;/.../tokenizer.json&quot;)</code></li><li><code>(format=:unigram, path=&quot;/.../unigram.tsv&quot;)</code></li><li><code>(format=:bpe_gpt2, vocab_json=&quot;/.../vocab.json&quot;, merges_txt=&quot;/.../merges.txt&quot;)</code></li><li><code>(format=:bpe_encoder, encoder_json=&quot;/.../encoder.json&quot;, vocab_bpe=&quot;/.../vocab.bpe&quot;)</code></li><li><code>(format=:wordpiece, vocab_txt=&quot;/.../vocab.txt&quot;)</code> (alias)</li><li><code>(format=:sentencepiece_model, model_file=&quot;/.../tokenizer.model&quot;)</code> (alias)</li><li><code>(format=:tiktoken, encoding_file=&quot;/.../o200k_base.tiktoken&quot;)</code> (alias)</li><li><code>(format=:hf_tokenizer_json, tokenizer_json=&quot;/.../tokenizer.json&quot;)</code> (alias)</li><li><code>(format=:unigram, unigram_tsv=&quot;/.../unigram.tsv&quot;)</code> (alias)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/io.jl#L123-L137">source</a></section><section><div><p>Load tokenizer from a <code>FilesSpec</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/io.jl#L184-L186">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.detect_tokenizer_format"><a class="docstring-binding" href="#KeemenaSubwords.detect_tokenizer_format"><code>KeemenaSubwords.detect_tokenizer_format</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>Detect tokenizer format from a local file or directory.</p><p>Returns one of symbols such as <code>:hf_tokenizer_json</code>, <code>:bpe_gpt2</code>, <code>:bpe_encoder</code>, <code>:sentencepiece_model</code>, <code>:tiktoken</code>, <code>:wordpiece</code>, <code>:bpe</code>, or <code>:unigram</code>.</p><p>Examples:</p><ul><li><code>detect_tokenizer_format(&quot;/path/to/model_dir&quot;)</code></li><li><code>detect_tokenizer_format(&quot;/path/to/tokenizer.model&quot;)</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/io.jl#L594-L603">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.detect_tokenizer_files"><a class="docstring-binding" href="#KeemenaSubwords.detect_tokenizer_files"><code>KeemenaSubwords.detect_tokenizer_files</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>Inspect a tokenizer directory and return detected candidate files.</p><p>Example: <code>detect_tokenizer_files(&quot;/path/to/model_dir&quot;)</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/io.jl#L554-L559">source</a></section></details></article><p>Structured encoding and file-spec APIs are also part of the public surface: <code>TokenizationResult</code>, <code>FilesSpec</code>, <code>encode_result</code>, <code>encode_batch_result</code>.</p><h2 id="Registry-and-Installation-APIs"><a class="docs-heading-anchor" href="#Registry-and-Installation-APIs">Registry and Installation APIs</a><a id="Registry-and-Installation-APIs-1"></a><a class="docs-heading-anchor-permalink" href="#Registry-and-Installation-APIs" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="KeemenaSubwords.available_models"><a class="docstring-binding" href="#KeemenaSubwords.available_models"><code>KeemenaSubwords.available_models</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>List available built-in model names.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/models.jl#L457-L459">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.describe_model"><a class="docstring-binding" href="#KeemenaSubwords.describe_model"><code>KeemenaSubwords.describe_model</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>Describe a built-in model.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/models.jl#L996-L998">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.model_path"><a class="docstring-binding" href="#KeemenaSubwords.model_path"><code>KeemenaSubwords.model_path</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>Resolve built-in model name to on-disk path.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/models.jl#L1054-L1056">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.prefetch_models"><a class="docstring-binding" href="#KeemenaSubwords.prefetch_models"><code>KeemenaSubwords.prefetch_models</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>Ensure artifact-backed built-in models are present on disk.</p><p>Returns a dictionary of <code>key =&gt; is_available</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/models.jl#L896-L900">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.register_local_model!"><a class="docstring-binding" href="#KeemenaSubwords.register_local_model!"><code>KeemenaSubwords.register_local_model!</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>Register a local tokenizer path under a symbolic key and persist it in the cache registry.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/models.jl#L635-L637">source</a></section><section><div><p>Register local model files by explicit specification.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/models.jl#L678-L680">source</a></section><section><div><p>Register local model files from a <code>FilesSpec</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/models.jl#L717-L719">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.install_model!"><a class="docstring-binding" href="#KeemenaSubwords.install_model!"><code>KeemenaSubwords.install_model!</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>Install an installable-gated tokenizer into the user cache and register it by key.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/models.jl#L812-L814">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.install_llama2_tokenizer!"><a class="docstring-binding" href="#KeemenaSubwords.install_llama2_tokenizer!"><code>KeemenaSubwords.install_llama2_tokenizer!</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>Install the gated LLaMA 2 tokenizer files into local cache and register them.</p><p>This is a convenience wrapper over <code>install_model!(:llama2_tokenizer; ...)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/models.jl#L866-L870">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.install_llama3_8b_tokenizer!"><a class="docstring-binding" href="#KeemenaSubwords.install_llama3_8b_tokenizer!"><code>KeemenaSubwords.install_llama3_8b_tokenizer!</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>Install the gated LLaMA 3 8B tokenizer files into local cache and register them.</p><p>This is a convenience wrapper over <code>install_model!(:llama3_8b_tokenizer; ...)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/models.jl#L873-L877">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.download_hf_files"><a class="docstring-binding" href="#KeemenaSubwords.download_hf_files"><code>KeemenaSubwords.download_hf_files</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>Download selected files from a Hugging Face repository revision into cache.</p><p>This helper is opt-in and useful for user-managed / gated tokenizers.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/models.jl#L766-L770">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.recommended_defaults_for_llms"><a class="docstring-binding" href="#KeemenaSubwords.recommended_defaults_for_llms"><code>KeemenaSubwords.recommended_defaults_for_llms</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>Recommended built-in keys for LLM-oriented default prefetching.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/models.jl#L880-L882">source</a></section></details></article><p><code>register_external_model!</code> remains available as a deprecated compatibility alias; prefer <code>register_local_model!</code> in new code.</p><h2 id="Full-Exported-API"><a class="docs-heading-anchor" href="#Full-Exported-API">Full Exported API</a><a id="Full-Exported-API-1"></a><a class="docs-heading-anchor-permalink" href="#Full-Exported-API" title="Permalink"></a></h2><article><details class="docstring" open="true"><summary id="KeemenaSubwords.AbstractSubwordTokenizer"><a class="docstring-binding" href="#KeemenaSubwords.AbstractSubwordTokenizer"><code>KeemenaSubwords.AbstractSubwordTokenizer</code></a> — <span class="docstring-category">Type</span></summary><section><div><p>Abstract parent type for all subword tokenizers.</p><p>Tokenizers are callable and support: <code>tokenizer(text::AbstractString) -&gt; Vector{String}</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/types.jl#L1-L6">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.FilesSpec"><a class="docstring-binding" href="#KeemenaSubwords.FilesSpec"><code>KeemenaSubwords.FilesSpec</code></a> — <span class="docstring-category">Type</span></summary><section><div><p>Structured file specification for local tokenizer loading/registration.</p><p>Use <code>path</code> for single-file formats and explicit pairs for multi-file formats.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/types.jl#L19-L23">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.SubwordVocabulary"><a class="docstring-binding" href="#KeemenaSubwords.SubwordVocabulary"><code>KeemenaSubwords.SubwordVocabulary</code></a> — <span class="docstring-category">Type</span></summary><section><div><p>Vocabulary container with forward/reverse lookup and special token IDs.</p><p>IDs are 1-based.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/vocab.jl#L1-L5">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.TokenizationResult"><a class="docstring-binding" href="#KeemenaSubwords.TokenizationResult"><code>KeemenaSubwords.TokenizationResult</code></a> — <span class="docstring-category">Type</span></summary><section><div><p>Structured tokenization output for downstream pipelines.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/types.jl#L73-L75">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.TokenizerMetadata"><a class="docstring-binding" href="#KeemenaSubwords.TokenizerMetadata"><code>KeemenaSubwords.TokenizerMetadata</code></a> — <span class="docstring-category">Type</span></summary><section><div><p>Common metadata for tokenizer instances.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/types.jl#L9-L11">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.available_models-Tuple{}"><a class="docstring-binding" href="#KeemenaSubwords.available_models-Tuple{}"><code>KeemenaSubwords.available_models</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>List available built-in model names.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/models.jl#L457-L459">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.bos_id-Tuple{AbstractSubwordTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.bos_id-Tuple{AbstractSubwordTokenizer}"><code>KeemenaSubwords.bos_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>BOS token ID if available.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/types.jl#L190-L192">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.bos_id-Tuple{BPETokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.bos_id-Tuple{BPETokenizer}"><code>KeemenaSubwords.bos_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>BOS token ID if available.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bpe.jl#L148-L150">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.bos_id-Tuple{ByteBPETokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.bos_id-Tuple{ByteBPETokenizer}"><code>KeemenaSubwords.bos_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>BOS token ID if available.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bytebpe.jl#L157-L159">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.bos_id-Tuple{SentencePieceTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.bos_id-Tuple{SentencePieceTokenizer}"><code>KeemenaSubwords.bos_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>BOS token ID if available.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/sentencepiece.jl#L198-L200">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.bos_id-Tuple{SubwordVocabulary}"><a class="docstring-binding" href="#KeemenaSubwords.bos_id-Tuple{SubwordVocabulary}"><code>KeemenaSubwords.bos_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Return beginning-of-sequence token ID if available.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/vocab.jl#L86-L88">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.bos_id-Tuple{TiktokenTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.bos_id-Tuple{TiktokenTokenizer}"><code>KeemenaSubwords.bos_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>BOS token ID if available.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/tiktoken.jl#L172-L174">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.bos_id-Tuple{UnigramTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.bos_id-Tuple{UnigramTokenizer}"><code>KeemenaSubwords.bos_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>BOS token ID if available.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/unigram.jl#L139-L141">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.bos_id-Tuple{WordPieceTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.bos_id-Tuple{WordPieceTokenizer}"><code>KeemenaSubwords.bos_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>BOS token ID if available.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/wordpiece.jl#L149-L151">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.decode-Tuple{AbstractSubwordTokenizer, AbstractVector{Int64}}"><a class="docstring-binding" href="#KeemenaSubwords.decode-Tuple{AbstractSubwordTokenizer, AbstractVector{Int64}}"><code>KeemenaSubwords.decode</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Decode token IDs into text.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/types.jl#L134-L136">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.decode-Tuple{BPETokenizer, AbstractVector{Int64}}"><a class="docstring-binding" href="#KeemenaSubwords.decode-Tuple{BPETokenizer, AbstractVector{Int64}}"><code>KeemenaSubwords.decode</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Decode token IDs to text.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bpe.jl#L94-L96">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.decode-Tuple{ByteBPETokenizer, AbstractVector{Int64}}"><a class="docstring-binding" href="#KeemenaSubwords.decode-Tuple{ByteBPETokenizer, AbstractVector{Int64}}"><code>KeemenaSubwords.decode</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Decode byte-level BPE IDs back to text.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bytebpe.jl#L84-L86">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.decode-Tuple{SentencePieceTokenizer, AbstractVector{Int64}}"><a class="docstring-binding" href="#KeemenaSubwords.decode-Tuple{SentencePieceTokenizer, AbstractVector{Int64}}"><code>KeemenaSubwords.decode</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Decode SentencePiece IDs back to text.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/sentencepiece.jl#L148-L150">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.decode-Tuple{TiktokenTokenizer, AbstractVector{Int64}}"><a class="docstring-binding" href="#KeemenaSubwords.decode-Tuple{TiktokenTokenizer, AbstractVector{Int64}}"><code>KeemenaSubwords.decode</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Decode tiktoken rank IDs to text.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/tiktoken.jl#L109-L111">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.decode-Tuple{UnigramTokenizer, AbstractVector{Int64}}"><a class="docstring-binding" href="#KeemenaSubwords.decode-Tuple{UnigramTokenizer, AbstractVector{Int64}}"><code>KeemenaSubwords.decode</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Decode unigram token IDs back to text.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/unigram.jl#L85-L87">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.decode-Tuple{WordPieceTokenizer, AbstractVector{Int64}}"><a class="docstring-binding" href="#KeemenaSubwords.decode-Tuple{WordPieceTokenizer, AbstractVector{Int64}}"><code>KeemenaSubwords.decode</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Decode WordPiece token IDs back into text.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/wordpiece.jl#L81-L83">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.describe_model-Tuple{Symbol}"><a class="docstring-binding" href="#KeemenaSubwords.describe_model-Tuple{Symbol}"><code>KeemenaSubwords.describe_model</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Describe a built-in model.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/models.jl#L996-L998">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.detect_tokenizer_files-Tuple{AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.detect_tokenizer_files-Tuple{AbstractString}"><code>KeemenaSubwords.detect_tokenizer_files</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Inspect a tokenizer directory and return detected candidate files.</p><p>Example: <code>detect_tokenizer_files(&quot;/path/to/model_dir&quot;)</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/io.jl#L554-L559">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.detect_tokenizer_format-Tuple{AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.detect_tokenizer_format-Tuple{AbstractString}"><code>KeemenaSubwords.detect_tokenizer_format</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Detect tokenizer format from a local file or directory.</p><p>Returns one of symbols such as <code>:hf_tokenizer_json</code>, <code>:bpe_gpt2</code>, <code>:bpe_encoder</code>, <code>:sentencepiece_model</code>, <code>:tiktoken</code>, <code>:wordpiece</code>, <code>:bpe</code>, or <code>:unigram</code>.</p><p>Examples:</p><ul><li><code>detect_tokenizer_format(&quot;/path/to/model_dir&quot;)</code></li><li><code>detect_tokenizer_format(&quot;/path/to/tokenizer.model&quot;)</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/io.jl#L594-L603">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.download_hf_files-Tuple{AbstractString, AbstractVector{&lt;:AbstractString}}"><a class="docstring-binding" href="#KeemenaSubwords.download_hf_files-Tuple{AbstractString, AbstractVector{&lt;:AbstractString}}"><code>KeemenaSubwords.download_hf_files</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Download selected files from a Hugging Face repository revision into cache.</p><p>This helper is opt-in and useful for user-managed / gated tokenizers.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/models.jl#L766-L770">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.encode-Tuple{AbstractSubwordTokenizer, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.encode-Tuple{AbstractSubwordTokenizer, AbstractString}"><code>KeemenaSubwords.encode</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Encode text into token IDs.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/types.jl#L122-L124">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.encode-Tuple{BPETokenizer, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.encode-Tuple{BPETokenizer, AbstractString}"><code>KeemenaSubwords.encode</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Encode text to token IDs.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bpe.jl#L74-L76">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.encode-Tuple{ByteBPETokenizer, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.encode-Tuple{ByteBPETokenizer, AbstractString}"><code>KeemenaSubwords.encode</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Encode text to byte-level BPE IDs.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bytebpe.jl#L64-L66">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.encode-Tuple{SentencePieceTokenizer, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.encode-Tuple{SentencePieceTokenizer, AbstractString}"><code>KeemenaSubwords.encode</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Encode text to SentencePiece IDs.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/sentencepiece.jl#L128-L130">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.encode-Tuple{TiktokenTokenizer, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.encode-Tuple{TiktokenTokenizer, AbstractString}"><code>KeemenaSubwords.encode</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Encode text into tiktoken rank IDs (1-based in this package).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/tiktoken.jl#L61-L63">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.encode-Tuple{UnigramTokenizer, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.encode-Tuple{UnigramTokenizer, AbstractString}"><code>KeemenaSubwords.encode</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Encode text to unigram token IDs.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/unigram.jl#L65-L67">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.encode-Tuple{WordPieceTokenizer, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.encode-Tuple{WordPieceTokenizer, AbstractString}"><code>KeemenaSubwords.encode</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Encode text to WordPiece token IDs.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/wordpiece.jl#L59-L61">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.encode_batch_result-Tuple{AbstractSubwordTokenizer, AbstractVector{&lt;:AbstractString}}"><a class="docstring-binding" href="#KeemenaSubwords.encode_batch_result-Tuple{AbstractSubwordTokenizer, AbstractVector{&lt;:AbstractString}}"><code>KeemenaSubwords.encode_batch_result</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Batch variant of <code>encode_result</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/io.jl#L252-L254">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.encode_result"><a class="docstring-binding" href="#KeemenaSubwords.encode_result"><code>KeemenaSubwords.encode_result</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>Encode text and return a structured <code>TokenizationResult</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/types.jl#L129-L131">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.eos_id-Tuple{AbstractSubwordTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.eos_id-Tuple{AbstractSubwordTokenizer}"><code>KeemenaSubwords.eos_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>EOS token ID if available.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/types.jl#L197-L199">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.eos_id-Tuple{BPETokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.eos_id-Tuple{BPETokenizer}"><code>KeemenaSubwords.eos_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>EOS token ID if available.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bpe.jl#L153-L155">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.eos_id-Tuple{ByteBPETokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.eos_id-Tuple{ByteBPETokenizer}"><code>KeemenaSubwords.eos_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>EOS token ID if available.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bytebpe.jl#L162-L164">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.eos_id-Tuple{SentencePieceTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.eos_id-Tuple{SentencePieceTokenizer}"><code>KeemenaSubwords.eos_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>EOS token ID if available.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/sentencepiece.jl#L203-L205">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.eos_id-Tuple{SubwordVocabulary}"><a class="docstring-binding" href="#KeemenaSubwords.eos_id-Tuple{SubwordVocabulary}"><code>KeemenaSubwords.eos_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Return end-of-sequence token ID if available.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/vocab.jl#L91-L93">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.eos_id-Tuple{TiktokenTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.eos_id-Tuple{TiktokenTokenizer}"><code>KeemenaSubwords.eos_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>EOS token ID if available.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/tiktoken.jl#L177-L179">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.eos_id-Tuple{UnigramTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.eos_id-Tuple{UnigramTokenizer}"><code>KeemenaSubwords.eos_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>EOS token ID if available.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/unigram.jl#L144-L146">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.eos_id-Tuple{WordPieceTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.eos_id-Tuple{WordPieceTokenizer}"><code>KeemenaSubwords.eos_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>EOS token ID if available.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/wordpiece.jl#L154-L156">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.export_tokenizer-Tuple{AbstractSubwordTokenizer, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.export_tokenizer-Tuple{AbstractSubwordTokenizer, AbstractString}"><code>KeemenaSubwords.export_tokenizer</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Export tokenizer to external formats.</p><p>Supported <code>format</code> values:</p><ul><li><code>:internal</code></li><li><code>:bpe</code> / <code>:bpe_gpt2</code></li><li><code>:wordpiece_vocab</code></li><li><code>:unigram_tsv</code></li><li><code>:sentencepiece_model</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/io.jl#L470-L479">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.id_to_token-Tuple{AbstractSubwordTokenizer, Int64}"><a class="docstring-binding" href="#KeemenaSubwords.id_to_token-Tuple{AbstractSubwordTokenizer, Int64}"><code>KeemenaSubwords.id_to_token</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Reverse token lookup.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/types.jl#L148-L150">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.id_to_token-Tuple{BPETokenizer, Int64}"><a class="docstring-binding" href="#KeemenaSubwords.id_to_token-Tuple{BPETokenizer, Int64}"><code>KeemenaSubwords.id_to_token</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Reverse token lookup.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bpe.jl#L118-L120">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.id_to_token-Tuple{ByteBPETokenizer, Int64}"><a class="docstring-binding" href="#KeemenaSubwords.id_to_token-Tuple{ByteBPETokenizer, Int64}"><code>KeemenaSubwords.id_to_token</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Reverse token lookup.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bytebpe.jl#L127-L129">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.id_to_token-Tuple{SentencePieceTokenizer, Int64}"><a class="docstring-binding" href="#KeemenaSubwords.id_to_token-Tuple{SentencePieceTokenizer, Int64}"><code>KeemenaSubwords.id_to_token</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Reverse token lookup.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/sentencepiece.jl#L168-L170">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.id_to_token-Tuple{SubwordVocabulary, Int64}"><a class="docstring-binding" href="#KeemenaSubwords.id_to_token-Tuple{SubwordVocabulary, Int64}"><code>KeemenaSubwords.id_to_token</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Map ID to token string.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/vocab.jl#L107-L109">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.id_to_token-Tuple{TiktokenTokenizer, Int64}"><a class="docstring-binding" href="#KeemenaSubwords.id_to_token-Tuple{TiktokenTokenizer, Int64}"><code>KeemenaSubwords.id_to_token</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Reverse token lookup.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/tiktoken.jl#L136-L138">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.id_to_token-Tuple{UnigramTokenizer, Int64}"><a class="docstring-binding" href="#KeemenaSubwords.id_to_token-Tuple{UnigramTokenizer, Int64}"><code>KeemenaSubwords.id_to_token</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Reverse token lookup.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/unigram.jl#L109-L111">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.id_to_token-Tuple{WordPieceTokenizer, Int64}"><a class="docstring-binding" href="#KeemenaSubwords.id_to_token-Tuple{WordPieceTokenizer, Int64}"><code>KeemenaSubwords.id_to_token</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Reverse token lookup.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/wordpiece.jl#L119-L121">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.install_llama2_tokenizer!-Tuple{}"><a class="docstring-binding" href="#KeemenaSubwords.install_llama2_tokenizer!-Tuple{}"><code>KeemenaSubwords.install_llama2_tokenizer!</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Install the gated LLaMA 2 tokenizer files into local cache and register them.</p><p>This is a convenience wrapper over <code>install_model!(:llama2_tokenizer; ...)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/models.jl#L866-L870">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.install_llama3_8b_tokenizer!-Tuple{}"><a class="docstring-binding" href="#KeemenaSubwords.install_llama3_8b_tokenizer!-Tuple{}"><code>KeemenaSubwords.install_llama3_8b_tokenizer!</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Install the gated LLaMA 3 8B tokenizer files into local cache and register them.</p><p>This is a convenience wrapper over <code>install_model!(:llama3_8b_tokenizer; ...)</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/models.jl#L873-L877">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.install_model!-Tuple{Symbol}"><a class="docstring-binding" href="#KeemenaSubwords.install_model!-Tuple{Symbol}"><code>KeemenaSubwords.install_model!</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Install an installable-gated tokenizer into the user cache and register it by key.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/models.jl#L812-L814">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.keemena_callable-Tuple{AbstractSubwordTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.keemena_callable-Tuple{AbstractSubwordTokenizer}"><code>KeemenaSubwords.keemena_callable</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Return a function compatible with KeemenaPreprocessing&#39;s callable tokenizer contract.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/types.jl#L96-L98">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.level_key-Tuple{AbstractSubwordTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.level_key-Tuple{AbstractSubwordTokenizer}"><code>KeemenaSubwords.level_key</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Level key used by KeemenaPreprocessing for callable tokenizers.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/types.jl#L109-L111">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.load_bpe-Tuple{AbstractString, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.load_bpe-Tuple{AbstractString, AbstractString}"><code>KeemenaSubwords.load_bpe</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Load a BPE tokenizer from explicit vocab + merges paths.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bpe.jl#L26-L28">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.load_bpe-Tuple{AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.load_bpe-Tuple{AbstractString}"><code>KeemenaSubwords.load_bpe</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Load a BPE tokenizer from either a directory (<code>vocab.txt</code> + <code>merges.txt</code>) or a vocab file path.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bpe.jl#L9-L11">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.load_bpe_encoder-Tuple{AbstractString, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.load_bpe_encoder-Tuple{AbstractString, AbstractString}"><code>KeemenaSubwords.load_bpe_encoder</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Load GPT-2 encoder variant from <code>encoder.json</code> + <code>vocab.bpe</code>.</p><p>Example: <code>load_bpe_encoder(&quot;/path/to/encoder.json&quot;, &quot;/path/to/vocab.bpe&quot;)</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/io.jl#L948-L953">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.load_bpe_gpt2-Tuple{AbstractString, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.load_bpe_gpt2-Tuple{AbstractString, AbstractString}"><code>KeemenaSubwords.load_bpe_gpt2</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Load GPT-2 / RoBERTa style BPE from <code>vocab.json</code> + <code>merges.txt</code>.</p><p>Example: <code>load_bpe_gpt2(&quot;/path/to/vocab.json&quot;, &quot;/path/to/merges.txt&quot;)</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/io.jl#L896-L901">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.load_bytebpe-Tuple{AbstractString, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.load_bytebpe-Tuple{AbstractString, AbstractString}"><code>KeemenaSubwords.load_bytebpe</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Load a byte-level BPE tokenizer from explicit vocab + merges paths.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bytebpe.jl#L25-L27">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.load_bytebpe-Tuple{AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.load_bytebpe-Tuple{AbstractString}"><code>KeemenaSubwords.load_bytebpe</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Load a byte-level BPE tokenizer from a directory (<code>vocab.txt</code> + <code>merges.txt</code>) or vocab path.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bytebpe.jl#L8-L10">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.load_hf_tokenizer_json-Tuple{AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.load_hf_tokenizer_json-Tuple{AbstractString}"><code>KeemenaSubwords.load_hf_tokenizer_json</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Load a Hugging Face <code>tokenizer.json</code> tokenizer in pure Julia.</p><p>Expected files:</p><ul><li><code>tokenizer.json</code> directly, or</li><li>a directory containing <code>tokenizer.json</code>.</li></ul><p>Examples:</p><ul><li><code>load_hf_tokenizer_json(&quot;/path/to/tokenizer.json&quot;)</code></li><li><code>load_hf_tokenizer_json(&quot;/path/to/model_dir&quot;)</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/huggingface_json/hf_json_loader.jl#L1-L11">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.load_sentencepiece-Tuple{AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.load_sentencepiece-Tuple{AbstractString}"><code>KeemenaSubwords.load_sentencepiece</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Load a SentencePiece <code>.model</code> file.</p><p>Supported inputs:</p><ul><li>standard SentencePiece binary protobuf <code>.model</code>/<code>.model.v3</code> payloads</li><li>Keemena text-exported model files:<ul><li>key/value lines (<code>type=unigram|bpe</code>, <code>whitespace_marker=▁</code>, <code>unk_token=&lt;unk&gt;</code>)</li><li>piece rows: <code>piece&lt;TAB&gt;token&lt;TAB&gt;score[&lt;TAB&gt;special_symbol]</code></li><li>bpe merge rows (for <code>type=bpe</code>): <code>merge&lt;TAB&gt;left&lt;TAB&gt;right</code></li></ul></li></ul><p>Examples:</p><ul><li><code>load_sentencepiece(&quot;/path/to/tokenizer.model&quot;; kind=:auto)</code></li><li><code>load_sentencepiece(&quot;/path/to/tokenizer.model.v3&quot;; kind=:bpe)</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/sentencepiece.jl#L7-L20">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.load_tiktoken-Tuple{AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.load_tiktoken-Tuple{AbstractString}"><code>KeemenaSubwords.load_tiktoken</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Load a tiktoken encoding file (<code>*.tiktoken</code>).</p><p>The expected format is line-based: <code>&lt;base64_token_bytes&gt;&lt;space&gt;&lt;rank&gt;</code> where ranks are non-negative integers.</p><p>Examples:</p><ul><li><code>load_tiktoken(&quot;/path/to/o200k_base.tiktoken&quot;)</code></li><li><code>load_tiktoken(&quot;/path/to/tokenizer.model&quot;)</code> (when file contains tiktoken text lines)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/tiktoken.jl#L11-L21">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.load_tokenizer-Tuple{AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.load_tokenizer-Tuple{AbstractString}"><code>KeemenaSubwords.load_tokenizer</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Load tokenizer from file system path.</p><p>Common <code>format</code> contracts:</p><ul><li><code>:hf_tokenizer_json</code> -&gt; <code>tokenizer.json</code></li><li><code>:bpe_gpt2</code> -&gt; <code>vocab.json</code> + <code>merges.txt</code></li><li><code>:bpe_encoder</code> -&gt; <code>encoder.json</code> + <code>vocab.bpe</code></li><li><code>:wordpiece</code> / <code>:wordpiece_vocab</code> -&gt; <code>vocab.txt</code></li><li><code>:sentencepiece_model</code> -&gt; <code>*.model</code> / <code>*.model.v3</code> / <code>sentencepiece.bpe.model</code></li><li><code>:tiktoken</code> -&gt; <code>*.tiktoken</code> or tiktoken-text <code>tokenizer.model</code></li></ul><p>Examples:</p><ul><li><code>load_tokenizer(&quot;/path/to/model_dir&quot;)</code></li><li><code>load_tokenizer(&quot;/path/to/tokenizer.model&quot;; format=:tiktoken)</code></li><li><code>load_tokenizer(&quot;/path/to/tokenizer.json&quot;; format=:hf_tokenizer_json)</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/io.jl#L24-L39">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.load_tokenizer-Tuple{FilesSpec}"><a class="docstring-binding" href="#KeemenaSubwords.load_tokenizer-Tuple{FilesSpec}"><code>KeemenaSubwords.load_tokenizer</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Load tokenizer from a <code>FilesSpec</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/io.jl#L184-L186">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.load_tokenizer-Tuple{NamedTuple}"><a class="docstring-binding" href="#KeemenaSubwords.load_tokenizer-Tuple{NamedTuple}"><code>KeemenaSubwords.load_tokenizer</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Load tokenizer from a named specification.</p><p>Examples:</p><ul><li><code>(format=:wordpiece, path=&quot;/.../vocab.txt&quot;)</code></li><li><code>(format=:hf_tokenizer_json, path=&quot;/.../tokenizer.json&quot;)</code></li><li><code>(format=:unigram, path=&quot;/.../unigram.tsv&quot;)</code></li><li><code>(format=:bpe_gpt2, vocab_json=&quot;/.../vocab.json&quot;, merges_txt=&quot;/.../merges.txt&quot;)</code></li><li><code>(format=:bpe_encoder, encoder_json=&quot;/.../encoder.json&quot;, vocab_bpe=&quot;/.../vocab.bpe&quot;)</code></li><li><code>(format=:wordpiece, vocab_txt=&quot;/.../vocab.txt&quot;)</code> (alias)</li><li><code>(format=:sentencepiece_model, model_file=&quot;/.../tokenizer.model&quot;)</code> (alias)</li><li><code>(format=:tiktoken, encoding_file=&quot;/.../o200k_base.tiktoken&quot;)</code> (alias)</li><li><code>(format=:hf_tokenizer_json, tokenizer_json=&quot;/.../tokenizer.json&quot;)</code> (alias)</li><li><code>(format=:unigram, unigram_tsv=&quot;/.../unigram.tsv&quot;)</code> (alias)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/io.jl#L123-L137">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.load_tokenizer-Tuple{Symbol}"><a class="docstring-binding" href="#KeemenaSubwords.load_tokenizer-Tuple{Symbol}"><code>KeemenaSubwords.load_tokenizer</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Load tokenizer by built-in model name.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/io.jl#L1-L3">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.load_tokenizer-Tuple{Tuple{AbstractString, AbstractString}}"><a class="docstring-binding" href="#KeemenaSubwords.load_tokenizer-Tuple{Tuple{AbstractString, AbstractString}}"><code>KeemenaSubwords.load_tokenizer</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Load tokenizer from explicit <code>(vocab_path, merges_path)</code> tuple.</p><p>This tuple form is for classic BPE/byte-level BPE (<code>vocab.txt</code> + <code>merges.txt</code>) or explicit JSON-pair loaders (<code>vocab.json</code> + <code>merges.txt</code>, <code>encoder.json</code> + <code>vocab.bpe</code>) when accompanied by <code>format</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/io.jl#L90-L96">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.load_unigram-Tuple{AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.load_unigram-Tuple{AbstractString}"><code>KeemenaSubwords.load_unigram</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Load a Unigram tokenizer from <code>unigram.tsv</code> (file or directory).</p><p>Expected format (tab-separated): <code>token&lt;TAB&gt;score[&lt;TAB&gt;special_symbol]</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/unigram.jl#L9-L14">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.load_wordpiece-Tuple{AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.load_wordpiece-Tuple{AbstractString}"><code>KeemenaSubwords.load_wordpiece</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Load a WordPiece tokenizer from a vocab file path or a directory containing <code>vocab.txt</code>.</p><p>Examples:</p><ul><li><code>load_wordpiece(&quot;/path/to/vocab.txt&quot;)</code></li><li><code>load_wordpiece(&quot;/path/to/model_dir&quot;)</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/wordpiece.jl#L9-L15">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.model_info-Tuple{AbstractSubwordTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.model_info-Tuple{AbstractSubwordTokenizer}"><code>KeemenaSubwords.model_info</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Return model metadata.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/types.jl#L162-L164">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.model_info-Tuple{BPETokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.model_info-Tuple{BPETokenizer}"><code>KeemenaSubwords.model_info</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Tokenizer metadata.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bpe.jl#L133-L135">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.model_info-Tuple{ByteBPETokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.model_info-Tuple{ByteBPETokenizer}"><code>KeemenaSubwords.model_info</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Tokenizer metadata.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bytebpe.jl#L142-L144">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.model_info-Tuple{SentencePieceTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.model_info-Tuple{SentencePieceTokenizer}"><code>KeemenaSubwords.model_info</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Tokenizer metadata.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/sentencepiece.jl#L183-L185">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.model_info-Tuple{TiktokenTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.model_info-Tuple{TiktokenTokenizer}"><code>KeemenaSubwords.model_info</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Tokenizer metadata.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/tiktoken.jl#L154-L156">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.model_info-Tuple{UnigramTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.model_info-Tuple{UnigramTokenizer}"><code>KeemenaSubwords.model_info</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Tokenizer metadata.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/unigram.jl#L124-L126">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.model_info-Tuple{WordPieceTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.model_info-Tuple{WordPieceTokenizer}"><code>KeemenaSubwords.model_info</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Tokenizer metadata.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/wordpiece.jl#L134-L136">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.model_path-Tuple{Symbol}"><a class="docstring-binding" href="#KeemenaSubwords.model_path-Tuple{Symbol}"><code>KeemenaSubwords.model_path</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Resolve built-in model name to on-disk path.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/models.jl#L1054-L1056">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.normalize_text-Tuple{AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.normalize_text-Tuple{AbstractString}"><code>KeemenaSubwords.normalize_text</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Normalize text using an optional user-provided callable.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/normalization.jl#L1-L3">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.pad_id-Tuple{AbstractSubwordTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.pad_id-Tuple{AbstractSubwordTokenizer}"><code>KeemenaSubwords.pad_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Padding token ID if available.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/types.jl#L183-L185">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.pad_id-Tuple{BPETokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.pad_id-Tuple{BPETokenizer}"><code>KeemenaSubwords.pad_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Padding token ID if available.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bpe.jl#L143-L145">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.pad_id-Tuple{ByteBPETokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.pad_id-Tuple{ByteBPETokenizer}"><code>KeemenaSubwords.pad_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Padding token ID if available.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bytebpe.jl#L152-L154">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.pad_id-Tuple{SentencePieceTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.pad_id-Tuple{SentencePieceTokenizer}"><code>KeemenaSubwords.pad_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Padding token ID if available.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/sentencepiece.jl#L193-L195">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.pad_id-Tuple{SubwordVocabulary}"><a class="docstring-binding" href="#KeemenaSubwords.pad_id-Tuple{SubwordVocabulary}"><code>KeemenaSubwords.pad_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Return padding-token ID if available.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/vocab.jl#L81-L83">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.pad_id-Tuple{TiktokenTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.pad_id-Tuple{TiktokenTokenizer}"><code>KeemenaSubwords.pad_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Padding token ID if available.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/tiktoken.jl#L167-L169">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.pad_id-Tuple{UnigramTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.pad_id-Tuple{UnigramTokenizer}"><code>KeemenaSubwords.pad_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Padding token ID if available.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/unigram.jl#L134-L136">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.pad_id-Tuple{WordPieceTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.pad_id-Tuple{WordPieceTokenizer}"><code>KeemenaSubwords.pad_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Padding token ID if available.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/wordpiece.jl#L144-L146">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.prefetch_models"><a class="docstring-binding" href="#KeemenaSubwords.prefetch_models"><code>KeemenaSubwords.prefetch_models</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>Ensure artifact-backed built-in models are present on disk.</p><p>Returns a dictionary of <code>key =&gt; is_available</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/models.jl#L896-L900">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.prefetch_models_status"><a class="docstring-binding" href="#KeemenaSubwords.prefetch_models_status"><code>KeemenaSubwords.prefetch_models_status</code></a> — <span class="docstring-category">Function</span></summary><section><div><p>Return detailed prefetch status for built-in model keys.</p><p>Each value includes:</p><ul><li><code>available::Bool</code></li><li><code>method::Symbol</code> (<code>:artifact</code>, <code>:fallback_download</code>, <code>:already_present</code>, or <code>:failed</code>)</li><li><code>path::Union{Nothing,String}</code></li><li><code>error::Union{Nothing,String}</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/models.jl#L909-L917">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.recommended_defaults_for_llms-Tuple{}"><a class="docstring-binding" href="#KeemenaSubwords.recommended_defaults_for_llms-Tuple{}"><code>KeemenaSubwords.recommended_defaults_for_llms</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Recommended built-in keys for LLM-oriented default prefetching.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/models.jl#L880-L882">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.register_external_model!-Tuple{Symbol, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.register_external_model!-Tuple{Symbol, AbstractString}"><code>KeemenaSubwords.register_external_model!</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Deprecated alias kept for compatibility. Use <code>register_local_model!</code> instead.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/models.jl#L728-L730">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.register_local_model!-Tuple{Symbol, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.register_local_model!-Tuple{Symbol, AbstractString}"><code>KeemenaSubwords.register_local_model!</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Register a local tokenizer path under a symbolic key and persist it in the cache registry.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/models.jl#L635-L637">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.register_local_model!-Tuple{Symbol, FilesSpec}"><a class="docstring-binding" href="#KeemenaSubwords.register_local_model!-Tuple{Symbol, FilesSpec}"><code>KeemenaSubwords.register_local_model!</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Register local model files from a <code>FilesSpec</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/models.jl#L717-L719">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.register_local_model!-Tuple{Symbol, NamedTuple}"><a class="docstring-binding" href="#KeemenaSubwords.register_local_model!-Tuple{Symbol, NamedTuple}"><code>KeemenaSubwords.register_local_model!</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Register local model files by explicit specification.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/models.jl#L678-L680">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.save_tokenizer-Tuple{AbstractSubwordTokenizer, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.save_tokenizer-Tuple{AbstractSubwordTokenizer, AbstractString}"><code>KeemenaSubwords.save_tokenizer</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Save tokenizer to a canonical on-disk format.</p><p><code>format=:internal</code> chooses a tokenizer-family specific default:</p><ul><li><code>WordPieceTokenizer</code> -&gt; <code>vocab.txt</code></li><li><code>BPETokenizer</code> / <code>ByteBPETokenizer</code> -&gt; <code>vocab.txt</code> + <code>merges.txt</code></li><li><code>UnigramTokenizer</code> -&gt; <code>unigram.tsv</code></li><li><code>SentencePieceTokenizer</code> -&gt; <code>spm.model</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/io.jl#L452-L460">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.special_tokens-Tuple{AbstractSubwordTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.special_tokens-Tuple{AbstractSubwordTokenizer}"><code>KeemenaSubwords.special_tokens</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Return special token IDs keyed by symbol.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/types.jl#L169-L171">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.special_tokens-Tuple{BPETokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.special_tokens-Tuple{BPETokenizer}"><code>KeemenaSubwords.special_tokens</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Special token IDs.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bpe.jl#L128-L130">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.special_tokens-Tuple{ByteBPETokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.special_tokens-Tuple{ByteBPETokenizer}"><code>KeemenaSubwords.special_tokens</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Special token IDs.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bytebpe.jl#L137-L139">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.special_tokens-Tuple{SentencePieceTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.special_tokens-Tuple{SentencePieceTokenizer}"><code>KeemenaSubwords.special_tokens</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Special token IDs.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/sentencepiece.jl#L178-L180">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.special_tokens-Tuple{TiktokenTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.special_tokens-Tuple{TiktokenTokenizer}"><code>KeemenaSubwords.special_tokens</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Special token IDs.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/tiktoken.jl#L149-L151">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.special_tokens-Tuple{UnigramTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.special_tokens-Tuple{UnigramTokenizer}"><code>KeemenaSubwords.special_tokens</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Special token IDs.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/unigram.jl#L119-L121">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.special_tokens-Tuple{WordPieceTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.special_tokens-Tuple{WordPieceTokenizer}"><code>KeemenaSubwords.special_tokens</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Special token IDs.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/wordpiece.jl#L129-L131">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.token_to_id-Tuple{AbstractSubwordTokenizer, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.token_to_id-Tuple{AbstractSubwordTokenizer, AbstractString}"><code>KeemenaSubwords.token_to_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Forward token lookup.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/types.jl#L141-L143">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.token_to_id-Tuple{BPETokenizer, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.token_to_id-Tuple{BPETokenizer, AbstractString}"><code>KeemenaSubwords.token_to_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Forward token lookup.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bpe.jl#L113-L115">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.token_to_id-Tuple{ByteBPETokenizer, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.token_to_id-Tuple{ByteBPETokenizer, AbstractString}"><code>KeemenaSubwords.token_to_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Forward token lookup.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bytebpe.jl#L122-L124">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.token_to_id-Tuple{SentencePieceTokenizer, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.token_to_id-Tuple{SentencePieceTokenizer, AbstractString}"><code>KeemenaSubwords.token_to_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Forward token lookup.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/sentencepiece.jl#L163-L165">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.token_to_id-Tuple{SubwordVocabulary, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.token_to_id-Tuple{SubwordVocabulary, AbstractString}"><code>KeemenaSubwords.token_to_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Map token string to ID, falling back to :unk.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/vocab.jl#L96-L98">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.token_to_id-Tuple{TiktokenTokenizer, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.token_to_id-Tuple{TiktokenTokenizer, AbstractString}"><code>KeemenaSubwords.token_to_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Forward token lookup.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/tiktoken.jl#L126-L128">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.token_to_id-Tuple{UnigramTokenizer, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.token_to_id-Tuple{UnigramTokenizer, AbstractString}"><code>KeemenaSubwords.token_to_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Forward token lookup.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/unigram.jl#L104-L106">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.token_to_id-Tuple{WordPieceTokenizer, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.token_to_id-Tuple{WordPieceTokenizer, AbstractString}"><code>KeemenaSubwords.token_to_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Forward token lookup.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/wordpiece.jl#L114-L116">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.tokenize-Tuple{AbstractSubwordTokenizer, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.tokenize-Tuple{AbstractSubwordTokenizer, AbstractString}"><code>KeemenaSubwords.tokenize</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Tokenize text into subword pieces.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/types.jl#L115-L117">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.tokenize-Tuple{BPETokenizer, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.tokenize-Tuple{BPETokenizer, AbstractString}"><code>KeemenaSubwords.tokenize</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Tokenize with classic BPE merges.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bpe.jl#L60-L62">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.tokenize-Tuple{ByteBPETokenizer, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.tokenize-Tuple{ByteBPETokenizer, AbstractString}"><code>KeemenaSubwords.tokenize</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Tokenize text by first mapping bytes to unicode symbols, then applying BPE merges.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bytebpe.jl#L50-L52">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.tokenize-Tuple{SentencePieceTokenizer, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.tokenize-Tuple{SentencePieceTokenizer, AbstractString}"><code>KeemenaSubwords.tokenize</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Tokenize text with SentencePiece wrapper behavior.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/sentencepiece.jl#L111-L113">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.tokenize-Tuple{TiktokenTokenizer, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.tokenize-Tuple{TiktokenTokenizer, AbstractString}"><code>KeemenaSubwords.tokenize</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Tokenize text into <code>b64:&lt;...&gt;</code> token pieces.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/tiktoken.jl#L53-L55">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.tokenize-Tuple{UnigramTokenizer, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.tokenize-Tuple{UnigramTokenizer, AbstractString}"><code>KeemenaSubwords.tokenize</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Tokenize text using deterministic Viterbi segmentation.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/unigram.jl#L50-L52">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.tokenize-Tuple{WordPieceTokenizer, AbstractString}"><a class="docstring-binding" href="#KeemenaSubwords.tokenize-Tuple{WordPieceTokenizer, AbstractString}"><code>KeemenaSubwords.tokenize</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Greedy longest-match WordPiece tokenization.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/wordpiece.jl#L45-L47">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.train_unigram-Tuple{Any}"><a class="docstring-binding" href="#KeemenaSubwords.train_unigram-Tuple{Any}"><code>KeemenaSubwords.train_unigram</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>High-level Unigram training entry point.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/training.jl#L80-L82">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.train_wordpiece-Tuple{Any}"><a class="docstring-binding" href="#KeemenaSubwords.train_wordpiece-Tuple{Any}"><code>KeemenaSubwords.train_wordpiece</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Optional WordPiece training entry point.</p><p>This API is reserved for a later iteration.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/training.jl#L106-L110">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.unk_id-Tuple{AbstractSubwordTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.unk_id-Tuple{AbstractSubwordTokenizer}"><code>KeemenaSubwords.unk_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Unknown token ID.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/types.jl#L176-L178">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.unk_id-Tuple{BPETokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.unk_id-Tuple{BPETokenizer}"><code>KeemenaSubwords.unk_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Unknown token ID.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bpe.jl#L138-L140">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.unk_id-Tuple{ByteBPETokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.unk_id-Tuple{ByteBPETokenizer}"><code>KeemenaSubwords.unk_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Unknown token ID.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bytebpe.jl#L147-L149">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.unk_id-Tuple{SentencePieceTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.unk_id-Tuple{SentencePieceTokenizer}"><code>KeemenaSubwords.unk_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Unknown token ID.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/sentencepiece.jl#L188-L190">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.unk_id-Tuple{SubwordVocabulary}"><a class="docstring-binding" href="#KeemenaSubwords.unk_id-Tuple{SubwordVocabulary}"><code>KeemenaSubwords.unk_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Return unknown-token ID.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/vocab.jl#L73-L75">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.unk_id-Tuple{TiktokenTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.unk_id-Tuple{TiktokenTokenizer}"><code>KeemenaSubwords.unk_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Unknown token ID.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/tiktoken.jl#L159-L161">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.unk_id-Tuple{UnigramTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.unk_id-Tuple{UnigramTokenizer}"><code>KeemenaSubwords.unk_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Unknown token ID.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/unigram.jl#L129-L131">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.unk_id-Tuple{WordPieceTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.unk_id-Tuple{WordPieceTokenizer}"><code>KeemenaSubwords.unk_id</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Unknown token ID.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/wordpiece.jl#L139-L141">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.vocab_size-Tuple{AbstractSubwordTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.vocab_size-Tuple{AbstractSubwordTokenizer}"><code>KeemenaSubwords.vocab_size</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Vocabulary size.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/types.jl#L155-L157">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.vocab_size-Tuple{BPETokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.vocab_size-Tuple{BPETokenizer}"><code>KeemenaSubwords.vocab_size</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Vocabulary size.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bpe.jl#L123-L125">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.vocab_size-Tuple{ByteBPETokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.vocab_size-Tuple{ByteBPETokenizer}"><code>KeemenaSubwords.vocab_size</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Vocabulary size.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/bytebpe.jl#L132-L134">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.vocab_size-Tuple{SentencePieceTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.vocab_size-Tuple{SentencePieceTokenizer}"><code>KeemenaSubwords.vocab_size</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Vocabulary size.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/sentencepiece.jl#L173-L175">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.vocab_size-Tuple{SubwordVocabulary}"><a class="docstring-binding" href="#KeemenaSubwords.vocab_size-Tuple{SubwordVocabulary}"><code>KeemenaSubwords.vocab_size</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Vocabulary size.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/vocab.jl#L115-L117">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.vocab_size-Tuple{TiktokenTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.vocab_size-Tuple{TiktokenTokenizer}"><code>KeemenaSubwords.vocab_size</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Vocabulary size.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/tiktoken.jl#L144-L146">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.vocab_size-Tuple{UnigramTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.vocab_size-Tuple{UnigramTokenizer}"><code>KeemenaSubwords.vocab_size</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Vocabulary size.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/unigram.jl#L114-L116">source</a></section></details></article><article><details class="docstring" open="true"><summary id="KeemenaSubwords.vocab_size-Tuple{WordPieceTokenizer}"><a class="docstring-binding" href="#KeemenaSubwords.vocab_size-Tuple{WordPieceTokenizer}"><code>KeemenaSubwords.vocab_size</code></a> — <span class="docstring-category">Method</span></summary><section><div><p>Vocabulary size.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/1c1512d20575c8e8a6d2e7671822515950bd144e/src/wordpiece.jl#L124-L126">source</a></section></details></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../models/">« Built-In Models</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Wednesday 11 February 2026 05:34">Wednesday 11 February 2026</span>. Using Julia version 1.12.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
