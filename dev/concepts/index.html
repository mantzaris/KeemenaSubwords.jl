<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Concepts · KeemenaSubwords.jl</title><meta name="title" content="Concepts · KeemenaSubwords.jl"/><meta property="og:title" content="Concepts · KeemenaSubwords.jl"/><meta property="twitter:title" content="Concepts · KeemenaSubwords.jl"/><meta name="description" content="Documentation for KeemenaSubwords.jl."/><meta property="og:description" content="Documentation for KeemenaSubwords.jl."/><meta property="twitter:description" content="Documentation for KeemenaSubwords.jl."/><meta property="og:url" content="https://mantzaris.github.io/KeemenaSubwords.jl/concepts/"/><meta property="twitter:url" content="https://mantzaris.github.io/KeemenaSubwords.jl/concepts/"/><link rel="canonical" href="https://mantzaris.github.io/KeemenaSubwords.jl/concepts/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">KeemenaSubwords.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li class="is-active"><a class="tocitem" href>Concepts</a><ul class="internal"><li><a class="tocitem" href="#Where-This-Fits"><span>Where This Fits</span></a></li><li><a class="tocitem" href="#Token-Pieces-Vs-Token-Ids"><span>Token Pieces Vs Token Ids</span></a></li><li><a class="tocitem" href="#Tokenizer-Families-Supported"><span>Tokenizer Families Supported</span></a></li><li><a class="tocitem" href="#Special-Tokens-And-add_special_tokens"><span>Special Tokens And <code>add_special_tokens</code></span></a></li><li><a class="tocitem" href="#Structured-Encoding-And-Offsets"><span>Structured Encoding And Offsets</span></a></li><li><a class="tocitem" href="#Model-Registry-And-Caching"><span>Model Registry And Caching</span></a></li><li><a class="tocitem" href="#Loading-And-Exporting"><span>Loading And Exporting</span></a></li></ul></li><li><a class="tocitem" href="../quick_guide_recipes/">Quick Guide Recipes</a></li><li><a class="tocitem" href="../structured_outputs_and_batching/">Structured Outputs and Batching</a></li><li><a class="tocitem" href="../integration/">Integration</a></li><li><a class="tocitem" href="../normalization_offsets_contract/">Normalization &amp; Offsets</a></li><li><a class="tocitem" href="../offset_alignment_examples/">Offsets Alignment Examples</a></li><li><a class="tocitem" href="../loading/">Loading</a></li><li><a class="tocitem" href="../training/">Training</a></li><li><a class="tocitem" href="../formats/">Formats</a></li><li><a class="tocitem" href="../loading_local/">Loading Local</a></li><li><a class="tocitem" href="../llm_cookbook/">LLM Cookbook</a></li><li><a class="tocitem" href="../gated_models/">Gated Models</a></li><li><a class="tocitem" href="../troubleshooting/">Troubleshooting</a></li><li><a class="tocitem" href="../models/">Built-In Models</a></li><li><a class="tocitem" href="../api/">API Reference</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Concepts</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Concepts</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/mantzaris/KeemenaSubwords.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/mantzaris/KeemenaSubwords.jl/blob/main/docs/src/concepts.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Concepts"><a class="docs-heading-anchor" href="#Concepts">Concepts</a><a id="Concepts-1"></a><a class="docs-heading-anchor-permalink" href="#Concepts" title="Permalink"></a></h1><p>This page is a first-hour guide to the concepts you need for reliable tokenization and alignment workflows in KeemenaSubwords.</p><h2 id="Where-This-Fits"><a class="docs-heading-anchor" href="#Where-This-Fits">Where This Fits</a><a id="Where-This-Fits-1"></a><a class="docs-heading-anchor-permalink" href="#Where-This-Fits" title="Permalink"></a></h2><p>Typical Julia LLM preprocessing split:</p><ul><li><code>KeemenaPreprocessing</code>: produces normalized <code>clean_text</code>.</li><li><code>KeemenaSubwords</code>: turns text into token pieces and 1-based token ids.</li></ul><p>Recommended integration flow:</p><ol><li><code>clean_text = ...</code> from your preprocessing pipeline.</li><li><code>tokenization_text = tokenization_view(tokenizer, clean_text)</code>.</li><li><code>encode_result(tokenizer, tokenization_text; assume_normalized=true, return_offsets=true, return_masks=true, ...)</code>.</li></ol><h2 id="Token-Pieces-Vs-Token-Ids"><a class="docs-heading-anchor" href="#Token-Pieces-Vs-Token-Ids">Token Pieces Vs Token Ids</a><a id="Token-Pieces-Vs-Token-Ids-1"></a><a class="docs-heading-anchor-permalink" href="#Token-Pieces-Vs-Token-Ids" title="Permalink"></a></h2><ul><li><code>tokenize(tok, text)</code> returns token pieces (<code>Vector{String}</code>).</li><li><code>encode(tok, text; ...)</code> returns token ids (<code>Vector{Int}</code>).</li><li><code>decode(tok, ids)</code> maps ids back to text.</li></ul><pre><code class="language-julia hljs">using KeemenaSubwords

tok = load_tokenizer(:core_bpe_en)
text = &quot;Hello world&quot;

pieces = tokenize(tok, text)
ids = encode(tok, text; add_special_tokens=true)
decoded = decode(tok, ids)

(; pieces, ids, decoded)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(pieces = [&quot;&lt;unk&gt;&quot;, &quot;world&lt;/w&gt;&quot;], ids = [3, 1, 29, 4], decoded = &quot;&lt;unk&gt;world&quot;)</code></pre><p>KeemenaSubwords uses <strong>1-based token ids</strong>.</p><p>Convert to 0-based ids only when you need parity with external tooling:</p><pre><code class="language-julia hljs">ids_zero_based = ids .- 1
ids_julia = ids_zero_based .+ 1</code></pre><h2 id="Tokenizer-Families-Supported"><a class="docs-heading-anchor" href="#Tokenizer-Families-Supported">Tokenizer Families Supported</a><a id="Tokenizer-Families-Supported-1"></a><a class="docs-heading-anchor-permalink" href="#Tokenizer-Families-Supported" title="Permalink"></a></h2><ul><li>BPE (classic)<ul><li>Typical format symbols: <code>:bpe</code></li><li>Byte-level: no</li><li>Offset implication: spanful offsets are expected to be string-safe in normal usage.</li></ul></li><li>ByteBPE<ul><li>Typical format symbols: <code>:bytebpe</code></li><li>Byte-level: yes</li><li>Offset implication: offsets are valid codeunit spans, but may not always be safe Julia string slice boundaries on multibyte text.</li></ul></li><li>WordPiece<ul><li>Typical format symbols: <code>:wordpiece</code>, <code>:wordpiece_vocab</code></li><li>Byte-level: no</li><li>Offset implication: spanful offsets are expected to be string-safe in normal usage.</li></ul></li><li>Unigram TSV<ul><li>Typical format symbols: <code>:unigram</code>, <code>:unigram_tsv</code></li><li>Byte-level: no</li><li>Offset implication: spanful offsets are expected to be string-safe in normal usage.</li></ul></li><li>SentencePiece model<ul><li>Typical format symbols: <code>:sentencepiece_model</code></li><li>Byte-level: usually no</li><li>Offset implication: spanful offsets are expected to be string-safe for standard SentencePiece pipelines.</li></ul></li><li>tiktoken<ul><li>Typical format symbols: <code>:tiktoken</code></li><li>Byte-level: yes</li><li>Offset implication: use the same byte-level caveat as ByteBPE.</li></ul></li><li>HF tokenizer.json<ul><li>Typical format symbols: <code>:hf_tokenizer_json</code></li><li>Byte-level: depends on configured pipeline components</li><li>Offset implication: when ByteLevel components are present, use byte-level offset caveats.</li></ul></li></ul><h2 id="Special-Tokens-And-add_special_tokens"><a class="docs-heading-anchor" href="#Special-Tokens-And-add_special_tokens">Special Tokens And <code>add_special_tokens</code></a><a id="Special-Tokens-And-add_special_tokens-1"></a><a class="docs-heading-anchor-permalink" href="#Special-Tokens-And-add_special_tokens" title="Permalink"></a></h2><p>Inspect special token mappings and common ids:</p><pre><code class="language-julia hljs">using KeemenaSubwords

tok = load_tokenizer(:core_wordpiece_en)

specials = special_tokens(tok)
ids = (
    bos = try bos_id(tok) catch; nothing end,
    eos = try eos_id(tok) catch; nothing end,
    pad = try pad_id(tok) catch; nothing end,
    unk = try unk_id(tok) catch; nothing end,
)

(; specials, ids)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(specials = Dict(:pad =&gt; 1, :sep =&gt; 4, :unk =&gt; 2, :mask =&gt; 5, :cls =&gt; 3), ids = (bos = nothing, eos = nothing, pad = 1, unk = 2))</code></pre><p><code>add_special_tokens=true</code> asks the tokenizer/post-processor to insert framework specials (for example BOS/EOS or CLS/SEP).</p><p>Offset behavior:</p><ul><li>Inserted specials: <code>special_tokens_mask[i] == 1</code> and <code>offsets[i] == (0, 0)</code>.</li><li>Specials that appear in the input text as matched added tokens: <code>special_tokens_mask[i] == 1</code>, but offsets can still be real spans into the input text.</li></ul><h2 id="Structured-Encoding-And-Offsets"><a class="docs-heading-anchor" href="#Structured-Encoding-And-Offsets">Structured Encoding And Offsets</a><a id="Structured-Encoding-And-Offsets-1"></a><a class="docs-heading-anchor-permalink" href="#Structured-Encoding-And-Offsets" title="Permalink"></a></h2><p>Use <code>encode_result</code> when you need ids plus offsets and masks in one object (<code>TokenizationResult</code>).</p><pre><code class="language-julia hljs">using KeemenaSubwords

tok = load_tokenizer(:core_sentencepiece_unigram_en)
clean_text = &quot;Hello world&quot;
tokenization_text = tokenization_view(tok, clean_text)

result = encode_result(
    tok,
    tokenization_text;
    assume_normalized=true,
    add_special_tokens=true,
    return_offsets=true,
    return_masks=true,
)

(
    ids = result.ids,
    tokens = result.tokens,
    offsets = result.offsets,
    attention_mask = result.attention_mask,
    special_tokens_mask = result.special_tokens_mask,
    metadata = result.metadata,
)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">(ids = [2, 1, 5, 3], tokens = [&quot;&lt;s&gt;&quot;, &quot;&lt;unk&gt;&quot;, &quot;▁world&quot;, &quot;&lt;/s&gt;&quot;], offsets = [(0, 0), (1, 6), (7, 12), (0, 0)], attention_mask = [1, 1, 1, 1], special_tokens_mask = [1, 1, 0, 1], metadata = (format = :sentencepiece, model_name = &quot;core_sentencepiece_unigram_en&quot;, add_special_tokens = true, assume_normalized = true, offsets_coordinates = :utf8_codeunits, offsets_reference = :input_text))</code></pre><p>High-level offset contract:</p><ul><li>Coordinate system: UTF-8 codeunits.</li><li>Index base: 1.</li><li>Span style: half-open <code>[start, stop)</code>.</li><li>Sentinel for no-span tokens: <code>(0, 0)</code>.</li></ul><p>For the full contract and helper APIs, see <a href="../normalization_offsets_contract/">Normalization and Offsets Contract</a>. For worked alignment walkthroughs, see <a href="../offset_alignment_examples/">Offsets Alignment Examples</a>. For batching and padding recipes, see <a href="../structured_outputs_and_batching/">Structured Outputs and Batching</a>.</p><p>Recommended KeemenaPreprocessing alignment pattern:</p><pre><code class="language-julia hljs">tokenization_text = tokenization_view(tok, clean_text)
result = encode_result(
    tok,
    tokenization_text;
    assume_normalized=true,
    return_offsets=true,
    return_masks=true,
    add_special_tokens=true,
)</code></pre><h2 id="Model-Registry-And-Caching"><a class="docs-heading-anchor" href="#Model-Registry-And-Caching">Model Registry And Caching</a><a id="Model-Registry-And-Caching-1"></a><a class="docs-heading-anchor-permalink" href="#Model-Registry-And-Caching" title="Permalink"></a></h2><p>Use the registry APIs to discover models and the cache APIs to avoid reloading tokenizers repeatedly:</p><pre><code class="language-julia hljs">available_models(shipped=true)
describe_model(:core_bpe_en)
prefetch_models([:core_bpe_en, :core_wordpiece_en, :core_sentencepiece_unigram_en])

tok = get_tokenizer_cached(:core_bpe_en)

# Clear long-lived cached tokenizer instances when needed
# (for example to release memory or force a fresh reload).
clear_tokenizer_cache!()</code></pre><h2 id="Loading-And-Exporting"><a class="docs-heading-anchor" href="#Loading-And-Exporting">Loading And Exporting</a><a id="Loading-And-Exporting-1"></a><a class="docs-heading-anchor-permalink" href="#Loading-And-Exporting" title="Permalink"></a></h2><p>Pointers:</p><ul><li><a href="../loading/">Loading Tokenizers</a></li><li><a href="../loading_local/">Loading Tokenizers From Local Paths</a></li><li><a href="../formats/">Tokenizer Formats and Required Files</a></li></ul><p>Export APIs:</p><ul><li><code>export_tokenizer(tokenizer, out_dir; format=...)</code></li><li><code>save_tokenizer(tokenizer, out_dir; format=...)</code></li></ul><p>If you export with <code>format=:hf_tokenizer_json</code>, KeemenaSubwords writes <code>tokenizer.json</code> for HF-compatible fast tokenizer loading. Current scope details (for example companion config files) are documented in <a href="../formats/">Tokenizer Formats and Required Files</a>.</p><p>Placeholder examples below require local paths or gated access and are intentionally non-executable in docs:</p><pre><code class="language-julia hljs"># local path placeholder (non-executable)
tok = load_tokenizer(&quot;/path/to/tokenizer.model&quot;; format=:tiktoken)

# gated install placeholder (non-executable)
install_model!(:llama3_8b_tokenizer; token=ENV[&quot;HF_TOKEN&quot;])</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../">« Home</a><a class="docs-footer-nextpage" href="../quick_guide_recipes/">Quick Guide Recipes »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.16.1 on <span class="colophon-date" title="Monday 16 February 2026 22:03">Monday 16 February 2026</span>. Using Julia version 1.12.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
