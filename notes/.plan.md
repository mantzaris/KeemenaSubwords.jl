## 23) Offsets robustness and downstream-safe span utilities

### 23.1 Context

KeemenaSubwords offsets are now a strict contract:

* unit: UTF-8 codeunits
* base: 1-based
* span style: half-open [start, stop)
* sentinel: (0, 0) for "no source-text span"
* `special_tokens_mask` indicates special-token identity, but span participation is determined by offsets/sentinel
* `assume_normalized=true` guarantees offsets are computed relative to the exact input text passed to `encode_result` (tokenization_text)

KeemenaPreprocessing will build alignment maps using these offsets. The remaining risk is not "wrong offsets", but downstream consumers making incorrect assumptions (especially assuming offsets are always safe Julia string indices).

### 23.2 Goal

Make offsets safer and easier to consume downstream by:

1. Providing explicit helper APIs for "span participation" and safe span inspection.
2. Preventing common misuse: treating UTF-8 codeunit offsets as always-valid Julia string slicing indices.
3. Strengthening regression tests to cover byte-level + multibyte Unicode edge cases with these helpers.

### 23.3 Tasks

#### A) Add span-participation helper (sentinel vs empty vs non-empty)

Problem:

* `has_span(offset)` is only a sentinel check.
* Downstream aligners usually want to ignore empty spans too.

Tasks:

1. Add a new helper:

* `has_nonempty_span(offset::Tuple{Int,Int})::Bool`

  * definition: `has_span(offset) && offset[2] > offset[1]`

2. Export it and document it alongside `has_span`.

Acceptance:

* Downstream code can write a clear policy:

  * participate in span alignment iff `has_nonempty_span(offset)`.

#### B) Add downstream-safe span inspection utilities (do not assume Julia string slicing)

Problem:

* Offsets are codeunit indices; they may not be valid Julia string indices for SubString slicing.
* Users still want a safe way to inspect spans for debugging and for some alignment operations.

Tasks:

1. Add a helper that always works (codeunit-safe):

* `span_codeunits(text::AbstractString, offset::Tuple{Int,Int})::Vector{UInt8}`

  * sentinel or empty span -> `UInt8[]`
  * otherwise returns bytes `codeunits(text)[start:stop-1]` (respecting the half-open convention)

2. Add helpers for Julia-string slicing only when valid:

* `is_valid_string_boundary(text::AbstractString, idx::Int)::Bool`

  * true if `idx` is a valid Julia string index boundary OR `idx == ncodeunits(text) + 1`
  * false for idx <= 0 or idx > ncodeunits(text) + 1

* `try_span_substring(text::AbstractString, offset::Tuple{Int,Int})::Union{Nothing,String}`

  * sentinel or empty -> `""` (or `nothing`, but pick one and document it)
  * if both start/stop are valid string boundaries -> return substring respecting [start, stop)
  * else: return `nothing` (or a non-throwing placeholder)
  * must never throw

3. Add a tiny â€œspan lengthâ€ helper (optional but useful):

* `span_ncodeunits(offset)::Int`

  * sentinel -> 0
  * else -> max(0, stop-start)

Acceptance:

* Downstream can safely inspect spans without accidentally throwing on byte-level/multibyte edge cases.
* No change to the offset contract itself.

#### C) Strengthen invariants: add a non-overlap helper + tests where appropriate

Problem:

* Current tests enforce nondecreasing start/stop, but that still permits overlapping spans.
* For tokenization offsets, overlap is typically a bug (excluding sentinel/empty spans).

Tasks:

1. Add helper:

* `offsets_are_nonoverlapping(offsets::Vector{Tuple{Int,Int}}; ignore_sentinel::Bool=true, ignore_empty::Bool=true)::Bool`

  * iterate spanful offsets in order
  * enforce `next.start >= prev.stop` for participating spans
  * ignore sentinel (and optionally ignore empty spans)

2. Use in tests for representative tokenizers where it should hold:

* WordPiece
* SentencePiece Unigram
* HF tokenizer.json fixture(s)
* Classic BPE
* ByteBPE and tiktoken can be included too, as long as you ignore sentinel/empty spans

Acceptance:

* Any regression that introduces overlapping spans is caught early.

#### D) Add multibyte Unicode coverage specifically for byte-level offsets

Problem:

* Byte-level tokenizers can create spans that are correct in codeunits but not safe as Julia string boundaries.
* You want explicit tests proving:

  * the contract holds (bounds, sentinel rules)
  * the new helper utilities behave correctly and do not throw

Tasks:

1. Add a focused testset that runs byte-level cases on multibyte inputs, for example:

* "cafe\u0301" (combining mark)
* "Ã©" (precomposed)
* "ðŸ™‚" or "ðŸš€"
* mixed: "aðŸ™‚b"

2. For ByteBPE and the HF ByteLevel fixture:

* run `encode_result(...; assume_normalized=true, add_special_tokens=false, return_offsets=true, return_masks=true)`
* for each offset:

  * if `has_nonempty_span(offset)`:

    * `span_codeunits(text, offset)` returns a byte slice with length == stop-start
  * `try_span_substring` must never throw
  * if `try_span_substring` returns a string, it must match the corresponding substring on valid boundaries

Acceptance:

* Byte-level offsets are demonstrably safe to consume via the helper APIs, even on multibyte text.

#### E) Document the intended downstream recipe (KeemenaPreprocessing-friendly)

Tasks:

1. Update `notes/OffsetContract.md` (canonical) with a short section:

* "Offsets are codeunit spans; do not assume they are always valid Julia string slicing indices."
* Recommended downstream rule:

  * span participation iff `has_nonempty_span(offset)`
* Mention the new helper utilities (`span_codeunits`, `try_span_substring`).

2. Run the existing sync tool so docs stay in sync.

Acceptance:

* A KeemenaPreprocessing contributor can implement alignment correctly without guessing.

### 23.4 Acceptance checklist

* New helper APIs exist, exported, and documented.
* New tests cover:

  * empty vs sentinel spans
  * non-overlap invariants
  * byte-level multibyte input safety
* CI remains green (offline lane and download lane unchanged).

