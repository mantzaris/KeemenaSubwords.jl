## 22) Offset contract clarity + special token span semantics + drift prevention

### 22.1 Goals
Make the normalization + offsets contract fully unambiguous and "drop-in safe" for KeemenaPreprocessing alignment logic by addressing the remaining weak points:

1) Eliminate any ambiguity about offset indexing base (0 vs 1) and bounds.
2) Fully specify special token offset behavior for:
   - inserted special tokens (post-processor inserted)
   - special tokens matched from user text (added tokens present-in-text)
3) Lock down whitespace and ByteLevel-sensitive offset behavior with explicit contract tests.
4) Prevent documentation drift by having a single source of truth for the contract, with a sync/check tool in CI.
5) Provide small helper APIs so downstream packages never need to guess interpretation rules.

### 22.2 Design decisions to lock in
#### Offsets convention
- Coordinate unit: UTF-8 codeunits
- Index base: 1-based
- Span style: half-open [start, stop)
- Valid bounds for non-special spanful tokens:
  - 1 <= start <= stop <= ncodeunits(text) + 1

#### Sentinel and masking
- Sentinel for "no span" tokens:
  - offsets = (0, 0)
- Sentinel meaning:
  - (0, 0) is out-of-range in a 1-based scheme and therefore unambiguous.
- Masks:
  - special_tokens_mask[i] == 1 indicates a special token (either inserted or matched).
  - special_tokens_mask is not the span rule by itself. The span rule is whether offsets equal the sentinel.

#### Inserted vs present-in-text special tokens
- Inserted special tokens (TemplateProcessing, etc):
  - special_tokens_mask == 1
  - offsets == (0, 0)
- Special tokens matched from user text as added tokens:
  - special_tokens_mask == 1
  - offsets must be a real span into the input text (not sentinel)

Alignment guidance for KeemenaPreprocessing:
- Ignore tokens with sentinel offsets (0, 0) in span alignment.
- Do not automatically drop all mask==1 tokens, because some special tokens can be present-in-text and have real spans.

### 22.3 KeemenaSubwords tasks

#### A) Make offset base and sentinel programmatically queryable
Add and export the following helpers (minimal, stable API):
- offsets_coordinate_system()::Symbol              # already present, must remain :utf8_codeunits
- offsets_index_base()::Int                       # must return 1
- offsets_span_style()::Symbol                    # :half_open
- offsets_sentinel()::Tuple{Int,Int}              # (0, 0)
- has_span(offset::Tuple{Int,Int})::Bool          # true iff offset != offsets_sentinel()

Document these in the API reference.

Acceptance:
- KeemenaPreprocessing can assert the offset convention without parsing docs.

#### B) Make the offset base explicit everywhere (docs + docstrings + notes)
1) Update public docs:
- docs/src/normalization_offsets_contract.md
  - explicitly state: 1-based UTF-8 codeunit indices
  - explicitly state bounds and the stop == ncodeunits(text)+1 allowance
  - explicitly define sentinel meaning and the inserted vs present-in-text special rules
2) Update integration docs:
- docs/src/integration.md
  - add a short "Alignment rule" paragraph:
    - canonical coordinate system is tokenization_text
    - tokenization_text = tokenization_view(tokenizer, clean_text)
    - encode_result called with assume_normalized=true on tokenization_text
3) Update API docstrings:
- TokenizationResult docstring: base, bounds, sentinel, mask rules
- encode_result docstring: offsets are relative to the exact text argument passed to encode_result; assume_normalized does not change coordinate system
4) Choose canonical contract file and keep it authoritative:
- Make notes/OffsetContract.md the canonical source of truth
- Ensure it matches docs exactly on:
  - coordinate unit, base, bounds, sentinel, special rules, and alignment guidance

Acceptance:
- No reader can interpret offsets as 0-based after reading any docs or docstrings.

#### C) Implement inserted vs present-in-text special token span semantics
1) Confirm current behavior:
- Determine whether added-token matches in user text currently produce real offsets or sentinel offsets.
2) If needed, adjust offsets logic so that:
- inserted specials get sentinel offsets
- present-in-text specials keep real offsets (even if mask==1)
3) Add a targeted HF tokenizer.json fixture and tests:
- fixture includes:
  - TemplateProcessing that inserts specials
  - a special added token that can appear in user text
- tests assert:
  - inserted special token: mask==1 and offsets==(0,0)
  - present-in-text special token: mask==1 and offsets!= (0,0) and span matches substring

Acceptance:
- Special token offsets are deterministic and alignment-friendly.

#### D) Strengthen offset invariants tests across tokenizer families
Add a dedicated contract testset, for example:
- "Section 22 offsets base, bounds, and special span semantics"

For each representative tokenizer family (at least one each):
- tiktoken
- ByteBPE / GPT2-style BPE
- WordPiece
- SentencePiece Unigram and SentencePiece BPE compatibility
- Unigram TSV
- HF tokenizer.json (at least one realistic pipeline fixture)

Test requirements:
1) Bounds and sentinel:
- For a corpus subset of diverse strings (including whitespace-heavy):
  - result = encode_result(...; assume_normalized=true, return_offsets=true, return_masks=true, add_special_tokens=true)
  - for each i:
    - if offsets[i] == (0,0):
      - has_span(offsets[i]) == false
    - else:
      - 1 <= start <= stop <= ncodeunits(text) + 1
      - stop >= start
2) 1-based regression:
- Choose a string where a non-special token begins at the first codeunit.
- Assert start == 1 (not 0).
3) Monotonicity (spanful only):
- For i in sequence, enforce:
  - start and stop are nondecreasing for tokens with spans
  - ignore sentinel tokens in monotonicity checks

Acceptance:
- Any accidental change to base or sentinel breaks tests immediately.

#### E) ByteLevel and whitespace-sensitive contract tests
Add a clearly labeled testset focusing on:
- leading spaces
- repeated spaces
- tabs and newlines
- prefix-space behavior (where applicable)

Assertions:
- with assume_normalized=true, offsets refer to the exact provided text
- spanful offsets remain in-bounds and monotone

Acceptance:
- Offset bugs in the most error-prone whitespace cases are caught early.

#### F) Prevent doc drift with a sync/check tool
Add a tool:
- tools/sync_offset_contract.jl
  - copies notes/OffsetContract.md into docs/src/normalization_offsets_contract.md (or inserts into a marked region)
  - supports --check mode
Wire into CI (or existing verification scripts):
- julia --project=. tools/sync_offset_contract.jl --check

Acceptance:
- notes and docs cannot silently diverge.

### 22.4 Implementation order
1) Add helper APIs (offsets_index_base, offsets_sentinel, has_span, offsets_span_style).
2) Update docs + docstrings + notes (make base and special rules explicit).
3) Add special-token present-in-text vs inserted tests (and implement behavior if needed).
4) Add cross-family invariants tests and ByteLevel whitespace testset.
5) Add sync_offset_contract tool and CI check.
